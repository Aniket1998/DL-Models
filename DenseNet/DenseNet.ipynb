{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 300\n",
    "augmentations = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomCrop(32,padding=4),\n",
    "                                   transforms.ToTensor(),transforms.Normalize((0.0,0.0,0.0),(1.0,1.0,1.0))])\n",
    "test_tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.0,0.0,0.0),(1.0,1.0,1.0))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifardata',train=True,download=True,transform=augmentations)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifardata',train=False,download=True,transform=test_tf)\n",
    "trainval = torchvision.datasets.CIFAR10(root='./cifardata',train=True,download=True,transform=test_tf)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "evalloader = torch.utils.data.DataLoader(trainval,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseUnit(nn.Module):\n",
    "    def __init__(self,inchannels,growthrate):\n",
    "        super(DenseUnit,self).__init__()\n",
    "        self.conv = nn.Conv2d(inchannels,growthrate,3,padding=1,bias=False)\n",
    "        self.bn = nn.BatchNorm2d(inchannels)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn(x))\n",
    "        out = self.conv(out)\n",
    "        out = self.drop(out)\n",
    "        out = torch.cat([x,out],1)\n",
    "        return out\n",
    "    \n",
    "class Transition(nn.Module):\n",
    "    def __init__(self,inchannels,outchannels):\n",
    "        super(Transition,self).__init__()\n",
    "        self.conv = nn.Conv2d(inchannels,outchannels,1,bias=False)\n",
    "        self.bn = nn.BatchNorm2d(inchannels)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.avgpool = nn.AvgPool2d(2,stride=2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn(x))\n",
    "        out = self.conv(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.avgpool(out)\n",
    "        return out\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,growthrate,n_classes):\n",
    "        super(DenseNet,self).__init__()\n",
    "        n_channels = 16\n",
    "        self.conv = nn.Conv2d(3,n_channels,3,padding=1,bias=False)\n",
    "        self.block1 = self.dense_block(12,n_channels,growthrate)\n",
    "        n_channels += 12 * growthrate\n",
    "        self.t12 = Transition(n_channels,160)\n",
    "        n_channels = 160\n",
    "        self.block2 = self.dense_block(12,n_channels,growthrate)\n",
    "        n_channels += 12 * growthrate\n",
    "        self.t23 = Transition(n_channels,304)\n",
    "        n_channels = 304\n",
    "        self.block3 = self.dense_block(12,n_channels,growthrate)\n",
    "        n_channels += 12 * growthrate\n",
    "        self.bn = nn.BatchNorm2d(n_channels)\n",
    "        self.fc = nn.Linear(n_channels,n_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.t12(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.t23(x)\n",
    "        x = self.block3(x)\n",
    "        x = F.relu(self.bn(x))\n",
    "        x = F.avg_pool2d(x,x.size(2))\n",
    "        x = x.view(-1,x.size(1))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def dense_block(self,n_units,n_channels,growthrate):\n",
    "        layers = []\n",
    "        for i in range(n_units):\n",
    "            layers.append(DenseUnit(n_channels,growthrate))\n",
    "            n_channels += growthrate\n",
    "        return nn.Sequential(*layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = DenseNet(12,10)\n",
    "device = torch.device('cuda')\n",
    "densenet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(densenet.parameters(),lr=0.1,momentum=0.9,weight_decay=0.0001,nesterov=True) \n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones=[150,225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = densenet(inputs)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return (correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1,Minibatch 100] Average Training Loss : 1.929\n",
      "[Epoch 1,Minibatch 200] Average Training Loss : 1.710\n",
      "[Epoch 1,Minibatch 300] Average Training Loss : 1.561\n",
      "[Epoch 1,Minibatch 400] Average Training Loss : 1.454\n",
      "[Epoch 1,Minibatch 500] Average Training Loss : 1.387\n",
      "[Epoch 1,Minibatch 600] Average Training Loss : 1.306\n",
      "[Epoch 1,Minibatch 700] Average Training Loss : 1.229\n",
      "[Epoch 1] : Training Accuracy : 0.572 Test Accuracy 0.562\n",
      "[Epoch 2,Minibatch 100] Average Training Loss : 1.182\n",
      "[Epoch 2,Minibatch 200] Average Training Loss : 1.111\n",
      "[Epoch 2,Minibatch 300] Average Training Loss : 1.099\n",
      "[Epoch 2,Minibatch 400] Average Training Loss : 1.056\n",
      "[Epoch 2,Minibatch 500] Average Training Loss : 1.052\n",
      "[Epoch 2,Minibatch 600] Average Training Loss : 1.016\n",
      "[Epoch 2,Minibatch 700] Average Training Loss : 1.016\n",
      "[Epoch 2] : Training Accuracy : 0.646 Test Accuracy 0.636\n",
      "[Epoch 3,Minibatch 100] Average Training Loss : 0.961\n",
      "[Epoch 3,Minibatch 200] Average Training Loss : 0.960\n",
      "[Epoch 3,Minibatch 300] Average Training Loss : 0.937\n",
      "[Epoch 3,Minibatch 400] Average Training Loss : 0.937\n",
      "[Epoch 3,Minibatch 500] Average Training Loss : 0.926\n",
      "[Epoch 3,Minibatch 600] Average Training Loss : 0.909\n",
      "[Epoch 3,Minibatch 700] Average Training Loss : 0.933\n",
      "[Epoch 3] : Training Accuracy : 0.691 Test Accuracy 0.677\n",
      "[Epoch 4,Minibatch 100] Average Training Loss : 0.865\n",
      "[Epoch 4,Minibatch 200] Average Training Loss : 0.865\n",
      "[Epoch 4,Minibatch 300] Average Training Loss : 0.856\n",
      "[Epoch 4,Minibatch 400] Average Training Loss : 0.848\n",
      "[Epoch 4,Minibatch 500] Average Training Loss : 0.826\n",
      "[Epoch 4,Minibatch 600] Average Training Loss : 0.821\n",
      "[Epoch 4,Minibatch 700] Average Training Loss : 0.810\n",
      "[Epoch 4] : Training Accuracy : 0.720 Test Accuracy 0.704\n",
      "[Epoch 5,Minibatch 100] Average Training Loss : 0.794\n",
      "[Epoch 5,Minibatch 200] Average Training Loss : 0.803\n",
      "[Epoch 5,Minibatch 300] Average Training Loss : 0.769\n",
      "[Epoch 5,Minibatch 400] Average Training Loss : 0.770\n",
      "[Epoch 5,Minibatch 500] Average Training Loss : 0.756\n",
      "[Epoch 5,Minibatch 600] Average Training Loss : 0.758\n",
      "[Epoch 5,Minibatch 700] Average Training Loss : 0.773\n",
      "[Epoch 5] : Training Accuracy : 0.731 Test Accuracy 0.718\n",
      "[Epoch 6,Minibatch 100] Average Training Loss : 0.733\n",
      "[Epoch 6,Minibatch 200] Average Training Loss : 0.721\n",
      "[Epoch 6,Minibatch 300] Average Training Loss : 0.711\n",
      "[Epoch 6,Minibatch 400] Average Training Loss : 0.717\n",
      "[Epoch 6,Minibatch 500] Average Training Loss : 0.717\n",
      "[Epoch 6,Minibatch 600] Average Training Loss : 0.693\n",
      "[Epoch 6,Minibatch 700] Average Training Loss : 0.692\n",
      "[Epoch 6] : Training Accuracy : 0.758 Test Accuracy 0.745\n",
      "[Epoch 7,Minibatch 100] Average Training Loss : 0.660\n",
      "[Epoch 7,Minibatch 200] Average Training Loss : 0.654\n",
      "[Epoch 7,Minibatch 300] Average Training Loss : 0.667\n",
      "[Epoch 7,Minibatch 400] Average Training Loss : 0.667\n",
      "[Epoch 7,Minibatch 500] Average Training Loss : 0.647\n",
      "[Epoch 7,Minibatch 600] Average Training Loss : 0.643\n",
      "[Epoch 7,Minibatch 700] Average Training Loss : 0.645\n",
      "[Epoch 7] : Training Accuracy : 0.787 Test Accuracy 0.771\n",
      "[Epoch 8,Minibatch 100] Average Training Loss : 0.618\n",
      "[Epoch 8,Minibatch 200] Average Training Loss : 0.615\n",
      "[Epoch 8,Minibatch 300] Average Training Loss : 0.622\n",
      "[Epoch 8,Minibatch 400] Average Training Loss : 0.611\n",
      "[Epoch 8,Minibatch 500] Average Training Loss : 0.594\n",
      "[Epoch 8,Minibatch 600] Average Training Loss : 0.617\n",
      "[Epoch 8,Minibatch 700] Average Training Loss : 0.602\n",
      "[Epoch 8] : Training Accuracy : 0.788 Test Accuracy 0.774\n",
      "[Epoch 9,Minibatch 100] Average Training Loss : 0.593\n",
      "[Epoch 9,Minibatch 200] Average Training Loss : 0.584\n",
      "[Epoch 9,Minibatch 300] Average Training Loss : 0.589\n",
      "[Epoch 9,Minibatch 400] Average Training Loss : 0.599\n",
      "[Epoch 9,Minibatch 500] Average Training Loss : 0.567\n",
      "[Epoch 9,Minibatch 600] Average Training Loss : 0.584\n",
      "[Epoch 9,Minibatch 700] Average Training Loss : 0.571\n",
      "[Epoch 9] : Training Accuracy : 0.800 Test Accuracy 0.781\n",
      "[Epoch 10,Minibatch 100] Average Training Loss : 0.568\n",
      "[Epoch 10,Minibatch 200] Average Training Loss : 0.547\n",
      "[Epoch 10,Minibatch 300] Average Training Loss : 0.559\n",
      "[Epoch 10,Minibatch 400] Average Training Loss : 0.553\n",
      "[Epoch 10,Minibatch 500] Average Training Loss : 0.551\n",
      "[Epoch 10,Minibatch 600] Average Training Loss : 0.550\n",
      "[Epoch 10,Minibatch 700] Average Training Loss : 0.566\n",
      "[Epoch 10] : Training Accuracy : 0.807 Test Accuracy 0.796\n",
      "[Epoch 11,Minibatch 100] Average Training Loss : 0.557\n",
      "[Epoch 11,Minibatch 200] Average Training Loss : 0.502\n",
      "[Epoch 11,Minibatch 300] Average Training Loss : 0.552\n",
      "[Epoch 11,Minibatch 400] Average Training Loss : 0.549\n",
      "[Epoch 11,Minibatch 500] Average Training Loss : 0.533\n",
      "[Epoch 11,Minibatch 600] Average Training Loss : 0.549\n",
      "[Epoch 11,Minibatch 700] Average Training Loss : 0.551\n",
      "[Epoch 11] : Training Accuracy : 0.815 Test Accuracy 0.795\n",
      "[Epoch 12,Minibatch 100] Average Training Loss : 0.508\n",
      "[Epoch 12,Minibatch 200] Average Training Loss : 0.530\n",
      "[Epoch 12,Minibatch 300] Average Training Loss : 0.518\n",
      "[Epoch 12,Minibatch 400] Average Training Loss : 0.508\n",
      "[Epoch 12,Minibatch 500] Average Training Loss : 0.524\n",
      "[Epoch 12,Minibatch 600] Average Training Loss : 0.525\n",
      "[Epoch 12,Minibatch 700] Average Training Loss : 0.512\n",
      "[Epoch 12] : Training Accuracy : 0.814 Test Accuracy 0.801\n",
      "[Epoch 13,Minibatch 100] Average Training Loss : 0.494\n",
      "[Epoch 13,Minibatch 200] Average Training Loss : 0.493\n",
      "[Epoch 13,Minibatch 300] Average Training Loss : 0.495\n",
      "[Epoch 13,Minibatch 400] Average Training Loss : 0.519\n",
      "[Epoch 13,Minibatch 500] Average Training Loss : 0.501\n",
      "[Epoch 13,Minibatch 600] Average Training Loss : 0.522\n",
      "[Epoch 13,Minibatch 700] Average Training Loss : 0.482\n",
      "[Epoch 13] : Training Accuracy : 0.820 Test Accuracy 0.805\n",
      "[Epoch 14,Minibatch 100] Average Training Loss : 0.489\n",
      "[Epoch 14,Minibatch 200] Average Training Loss : 0.481\n",
      "[Epoch 14,Minibatch 300] Average Training Loss : 0.489\n",
      "[Epoch 14,Minibatch 400] Average Training Loss : 0.490\n",
      "[Epoch 14,Minibatch 500] Average Training Loss : 0.494\n",
      "[Epoch 14,Minibatch 600] Average Training Loss : 0.479\n",
      "[Epoch 14,Minibatch 700] Average Training Loss : 0.477\n",
      "[Epoch 14] : Training Accuracy : 0.822 Test Accuracy 0.803\n",
      "[Epoch 15,Minibatch 100] Average Training Loss : 0.455\n",
      "[Epoch 15,Minibatch 200] Average Training Loss : 0.479\n",
      "[Epoch 15,Minibatch 300] Average Training Loss : 0.468\n",
      "[Epoch 15,Minibatch 400] Average Training Loss : 0.476\n",
      "[Epoch 15,Minibatch 500] Average Training Loss : 0.473\n",
      "[Epoch 15,Minibatch 600] Average Training Loss : 0.467\n",
      "[Epoch 15,Minibatch 700] Average Training Loss : 0.472\n",
      "[Epoch 15] : Training Accuracy : 0.836 Test Accuracy 0.814\n",
      "[Epoch 16,Minibatch 100] Average Training Loss : 0.455\n",
      "[Epoch 16,Minibatch 200] Average Training Loss : 0.472\n",
      "[Epoch 16,Minibatch 300] Average Training Loss : 0.469\n",
      "[Epoch 16,Minibatch 400] Average Training Loss : 0.465\n",
      "[Epoch 16,Minibatch 500] Average Training Loss : 0.470\n",
      "[Epoch 16,Minibatch 600] Average Training Loss : 0.457\n",
      "[Epoch 16,Minibatch 700] Average Training Loss : 0.462\n",
      "[Epoch 16] : Training Accuracy : 0.815 Test Accuracy 0.795\n",
      "[Epoch 17,Minibatch 100] Average Training Loss : 0.449\n",
      "[Epoch 17,Minibatch 200] Average Training Loss : 0.457\n",
      "[Epoch 17,Minibatch 300] Average Training Loss : 0.451\n",
      "[Epoch 17,Minibatch 400] Average Training Loss : 0.452\n",
      "[Epoch 17,Minibatch 500] Average Training Loss : 0.456\n",
      "[Epoch 17,Minibatch 600] Average Training Loss : 0.466\n",
      "[Epoch 17,Minibatch 700] Average Training Loss : 0.467\n",
      "[Epoch 17] : Training Accuracy : 0.840 Test Accuracy 0.816\n",
      "[Epoch 18,Minibatch 100] Average Training Loss : 0.422\n",
      "[Epoch 18,Minibatch 200] Average Training Loss : 0.440\n",
      "[Epoch 18,Minibatch 300] Average Training Loss : 0.440\n",
      "[Epoch 18,Minibatch 400] Average Training Loss : 0.458\n",
      "[Epoch 18,Minibatch 500] Average Training Loss : 0.451\n",
      "[Epoch 18,Minibatch 600] Average Training Loss : 0.423\n",
      "[Epoch 18,Minibatch 700] Average Training Loss : 0.463\n",
      "[Epoch 18] : Training Accuracy : 0.850 Test Accuracy 0.830\n",
      "[Epoch 19,Minibatch 100] Average Training Loss : 0.438\n",
      "[Epoch 19,Minibatch 200] Average Training Loss : 0.401\n",
      "[Epoch 19,Minibatch 300] Average Training Loss : 0.418\n",
      "[Epoch 19,Minibatch 400] Average Training Loss : 0.448\n",
      "[Epoch 19,Minibatch 500] Average Training Loss : 0.457\n",
      "[Epoch 19,Minibatch 600] Average Training Loss : 0.441\n",
      "[Epoch 19,Minibatch 700] Average Training Loss : 0.453\n",
      "[Epoch 19] : Training Accuracy : 0.853 Test Accuracy 0.827\n",
      "[Epoch 20,Minibatch 100] Average Training Loss : 0.393\n",
      "[Epoch 20,Minibatch 200] Average Training Loss : 0.426\n",
      "[Epoch 20,Minibatch 300] Average Training Loss : 0.437\n",
      "[Epoch 20,Minibatch 400] Average Training Loss : 0.434\n",
      "[Epoch 20,Minibatch 500] Average Training Loss : 0.430\n",
      "[Epoch 20,Minibatch 600] Average Training Loss : 0.441\n",
      "[Epoch 20,Minibatch 700] Average Training Loss : 0.427\n",
      "[Epoch 20] : Training Accuracy : 0.844 Test Accuracy 0.822\n",
      "[Epoch 21,Minibatch 100] Average Training Loss : 0.430\n",
      "[Epoch 21,Minibatch 200] Average Training Loss : 0.386\n",
      "[Epoch 21,Minibatch 300] Average Training Loss : 0.417\n",
      "[Epoch 21,Minibatch 400] Average Training Loss : 0.423\n",
      "[Epoch 21,Minibatch 500] Average Training Loss : 0.431\n",
      "[Epoch 21,Minibatch 600] Average Training Loss : 0.432\n",
      "[Epoch 21,Minibatch 700] Average Training Loss : 0.438\n",
      "[Epoch 21] : Training Accuracy : 0.849 Test Accuracy 0.821\n",
      "[Epoch 22,Minibatch 100] Average Training Loss : 0.401\n",
      "[Epoch 22,Minibatch 200] Average Training Loss : 0.415\n",
      "[Epoch 22,Minibatch 300] Average Training Loss : 0.420\n",
      "[Epoch 22,Minibatch 400] Average Training Loss : 0.420\n",
      "[Epoch 22,Minibatch 500] Average Training Loss : 0.436\n",
      "[Epoch 22,Minibatch 600] Average Training Loss : 0.438\n",
      "[Epoch 22,Minibatch 700] Average Training Loss : 0.433\n",
      "[Epoch 22] : Training Accuracy : 0.848 Test Accuracy 0.822\n",
      "[Epoch 23,Minibatch 100] Average Training Loss : 0.404\n",
      "[Epoch 23,Minibatch 200] Average Training Loss : 0.411\n",
      "[Epoch 23,Minibatch 300] Average Training Loss : 0.401\n",
      "[Epoch 23,Minibatch 400] Average Training Loss : 0.420\n",
      "[Epoch 23,Minibatch 500] Average Training Loss : 0.420\n",
      "[Epoch 23,Minibatch 600] Average Training Loss : 0.402\n",
      "[Epoch 23,Minibatch 700] Average Training Loss : 0.413\n",
      "[Epoch 23] : Training Accuracy : 0.852 Test Accuracy 0.828\n",
      "[Epoch 24,Minibatch 100] Average Training Loss : 0.396\n",
      "[Epoch 24,Minibatch 200] Average Training Loss : 0.393\n",
      "[Epoch 24,Minibatch 300] Average Training Loss : 0.401\n",
      "[Epoch 24,Minibatch 400] Average Training Loss : 0.402\n",
      "[Epoch 24,Minibatch 500] Average Training Loss : 0.413\n",
      "[Epoch 24,Minibatch 600] Average Training Loss : 0.430\n",
      "[Epoch 24,Minibatch 700] Average Training Loss : 0.396\n",
      "[Epoch 24] : Training Accuracy : 0.859 Test Accuracy 0.833\n",
      "[Epoch 25,Minibatch 100] Average Training Loss : 0.372\n",
      "[Epoch 25,Minibatch 200] Average Training Loss : 0.394\n",
      "[Epoch 25,Minibatch 300] Average Training Loss : 0.390\n",
      "[Epoch 25,Minibatch 400] Average Training Loss : 0.392\n",
      "[Epoch 25,Minibatch 500] Average Training Loss : 0.404\n",
      "[Epoch 25,Minibatch 600] Average Training Loss : 0.404\n",
      "[Epoch 25,Minibatch 700] Average Training Loss : 0.405\n",
      "[Epoch 25] : Training Accuracy : 0.856 Test Accuracy 0.832\n",
      "[Epoch 26,Minibatch 100] Average Training Loss : 0.382\n",
      "[Epoch 26,Minibatch 200] Average Training Loss : 0.374\n",
      "[Epoch 26,Minibatch 300] Average Training Loss : 0.424\n",
      "[Epoch 26,Minibatch 400] Average Training Loss : 0.394\n",
      "[Epoch 26,Minibatch 500] Average Training Loss : 0.401\n",
      "[Epoch 26,Minibatch 600] Average Training Loss : 0.417\n",
      "[Epoch 26,Minibatch 700] Average Training Loss : 0.410\n",
      "[Epoch 26] : Training Accuracy : 0.865 Test Accuracy 0.836\n",
      "[Epoch 27,Minibatch 100] Average Training Loss : 0.394\n",
      "[Epoch 27,Minibatch 200] Average Training Loss : 0.390\n",
      "[Epoch 27,Minibatch 300] Average Training Loss : 0.398\n",
      "[Epoch 27,Minibatch 400] Average Training Loss : 0.389\n",
      "[Epoch 27,Minibatch 500] Average Training Loss : 0.398\n",
      "[Epoch 27,Minibatch 600] Average Training Loss : 0.397\n",
      "[Epoch 27,Minibatch 700] Average Training Loss : 0.400\n",
      "[Epoch 27] : Training Accuracy : 0.852 Test Accuracy 0.827\n",
      "[Epoch 28,Minibatch 100] Average Training Loss : 0.377\n",
      "[Epoch 28,Minibatch 200] Average Training Loss : 0.396\n",
      "[Epoch 28,Minibatch 300] Average Training Loss : 0.386\n",
      "[Epoch 28,Minibatch 400] Average Training Loss : 0.401\n",
      "[Epoch 28,Minibatch 500] Average Training Loss : 0.380\n",
      "[Epoch 28,Minibatch 600] Average Training Loss : 0.394\n",
      "[Epoch 28,Minibatch 700] Average Training Loss : 0.370\n",
      "[Epoch 28] : Training Accuracy : 0.869 Test Accuracy 0.841\n",
      "[Epoch 29,Minibatch 100] Average Training Loss : 0.381\n",
      "[Epoch 29,Minibatch 200] Average Training Loss : 0.404\n",
      "[Epoch 29,Minibatch 300] Average Training Loss : 0.375\n",
      "[Epoch 29,Minibatch 400] Average Training Loss : 0.376\n",
      "[Epoch 29,Minibatch 500] Average Training Loss : 0.415\n",
      "[Epoch 29,Minibatch 600] Average Training Loss : 0.386\n",
      "[Epoch 29,Minibatch 700] Average Training Loss : 0.395\n",
      "[Epoch 29] : Training Accuracy : 0.856 Test Accuracy 0.827\n",
      "[Epoch 30,Minibatch 100] Average Training Loss : 0.389\n",
      "[Epoch 30,Minibatch 200] Average Training Loss : 0.375\n",
      "[Epoch 30,Minibatch 300] Average Training Loss : 0.378\n",
      "[Epoch 30,Minibatch 400] Average Training Loss : 0.386\n",
      "[Epoch 30,Minibatch 500] Average Training Loss : 0.404\n",
      "[Epoch 30,Minibatch 600] Average Training Loss : 0.372\n",
      "[Epoch 30,Minibatch 700] Average Training Loss : 0.366\n",
      "[Epoch 30] : Training Accuracy : 0.850 Test Accuracy 0.825\n",
      "[Epoch 31,Minibatch 100] Average Training Loss : 0.374\n",
      "[Epoch 31,Minibatch 200] Average Training Loss : 0.382\n",
      "[Epoch 31,Minibatch 300] Average Training Loss : 0.384\n",
      "[Epoch 31,Minibatch 400] Average Training Loss : 0.379\n",
      "[Epoch 31,Minibatch 500] Average Training Loss : 0.376\n",
      "[Epoch 31,Minibatch 600] Average Training Loss : 0.388\n",
      "[Epoch 31,Minibatch 700] Average Training Loss : 0.359\n",
      "[Epoch 31] : Training Accuracy : 0.857 Test Accuracy 0.831\n",
      "[Epoch 32,Minibatch 100] Average Training Loss : 0.372\n",
      "[Epoch 32,Minibatch 200] Average Training Loss : 0.381\n",
      "[Epoch 32,Minibatch 300] Average Training Loss : 0.381\n",
      "[Epoch 32,Minibatch 400] Average Training Loss : 0.365\n",
      "[Epoch 32,Minibatch 500] Average Training Loss : 0.372\n",
      "[Epoch 32,Minibatch 600] Average Training Loss : 0.382\n",
      "[Epoch 32,Minibatch 700] Average Training Loss : 0.376\n",
      "[Epoch 32] : Training Accuracy : 0.863 Test Accuracy 0.836\n",
      "[Epoch 33,Minibatch 100] Average Training Loss : 0.346\n",
      "[Epoch 33,Minibatch 200] Average Training Loss : 0.355\n",
      "[Epoch 33,Minibatch 300] Average Training Loss : 0.382\n",
      "[Epoch 33,Minibatch 400] Average Training Loss : 0.367\n",
      "[Epoch 33,Minibatch 500] Average Training Loss : 0.396\n",
      "[Epoch 33,Minibatch 600] Average Training Loss : 0.377\n",
      "[Epoch 33,Minibatch 700] Average Training Loss : 0.365\n",
      "[Epoch 33] : Training Accuracy : 0.876 Test Accuracy 0.846\n",
      "[Epoch 34,Minibatch 100] Average Training Loss : 0.362\n",
      "[Epoch 34,Minibatch 200] Average Training Loss : 0.340\n",
      "[Epoch 34,Minibatch 300] Average Training Loss : 0.356\n",
      "[Epoch 34,Minibatch 400] Average Training Loss : 0.370\n",
      "[Epoch 34,Minibatch 500] Average Training Loss : 0.378\n",
      "[Epoch 34,Minibatch 600] Average Training Loss : 0.354\n",
      "[Epoch 34,Minibatch 700] Average Training Loss : 0.376\n",
      "[Epoch 34] : Training Accuracy : 0.868 Test Accuracy 0.838\n",
      "[Epoch 35,Minibatch 100] Average Training Loss : 0.350\n",
      "[Epoch 35,Minibatch 200] Average Training Loss : 0.375\n",
      "[Epoch 35,Minibatch 300] Average Training Loss : 0.360\n",
      "[Epoch 35,Minibatch 400] Average Training Loss : 0.372\n",
      "[Epoch 35,Minibatch 500] Average Training Loss : 0.362\n",
      "[Epoch 35,Minibatch 600] Average Training Loss : 0.356\n",
      "[Epoch 35,Minibatch 700] Average Training Loss : 0.357\n",
      "[Epoch 35] : Training Accuracy : 0.863 Test Accuracy 0.834\n",
      "[Epoch 36,Minibatch 100] Average Training Loss : 0.365\n",
      "[Epoch 36,Minibatch 200] Average Training Loss : 0.347\n",
      "[Epoch 36,Minibatch 300] Average Training Loss : 0.370\n",
      "[Epoch 36,Minibatch 400] Average Training Loss : 0.353\n",
      "[Epoch 36,Minibatch 500] Average Training Loss : 0.351\n",
      "[Epoch 36,Minibatch 600] Average Training Loss : 0.355\n",
      "[Epoch 36,Minibatch 700] Average Training Loss : 0.365\n",
      "[Epoch 36] : Training Accuracy : 0.869 Test Accuracy 0.843\n",
      "[Epoch 37,Minibatch 100] Average Training Loss : 0.359\n",
      "[Epoch 37,Minibatch 200] Average Training Loss : 0.354\n",
      "[Epoch 37,Minibatch 300] Average Training Loss : 0.340\n",
      "[Epoch 37,Minibatch 400] Average Training Loss : 0.378\n",
      "[Epoch 37,Minibatch 500] Average Training Loss : 0.354\n",
      "[Epoch 37,Minibatch 600] Average Training Loss : 0.361\n",
      "[Epoch 37,Minibatch 700] Average Training Loss : 0.356\n",
      "[Epoch 37] : Training Accuracy : 0.876 Test Accuracy 0.846\n",
      "[Epoch 38,Minibatch 100] Average Training Loss : 0.339\n",
      "[Epoch 38,Minibatch 200] Average Training Loss : 0.342\n",
      "[Epoch 38,Minibatch 300] Average Training Loss : 0.361\n",
      "[Epoch 38,Minibatch 400] Average Training Loss : 0.370\n",
      "[Epoch 38,Minibatch 500] Average Training Loss : 0.363\n",
      "[Epoch 38,Minibatch 600] Average Training Loss : 0.352\n",
      "[Epoch 38,Minibatch 700] Average Training Loss : 0.371\n",
      "[Epoch 38] : Training Accuracy : 0.876 Test Accuracy 0.847\n",
      "[Epoch 39,Minibatch 100] Average Training Loss : 0.361\n",
      "[Epoch 39,Minibatch 200] Average Training Loss : 0.351\n",
      "[Epoch 39,Minibatch 300] Average Training Loss : 0.351\n",
      "[Epoch 39,Minibatch 400] Average Training Loss : 0.351\n",
      "[Epoch 39,Minibatch 500] Average Training Loss : 0.358\n",
      "[Epoch 39,Minibatch 600] Average Training Loss : 0.357\n",
      "[Epoch 39,Minibatch 700] Average Training Loss : 0.332\n",
      "[Epoch 39] : Training Accuracy : 0.873 Test Accuracy 0.846\n",
      "[Epoch 40,Minibatch 100] Average Training Loss : 0.362\n",
      "[Epoch 40,Minibatch 200] Average Training Loss : 0.347\n",
      "[Epoch 40,Minibatch 300] Average Training Loss : 0.357\n",
      "[Epoch 40,Minibatch 400] Average Training Loss : 0.361\n",
      "[Epoch 40,Minibatch 500] Average Training Loss : 0.356\n",
      "[Epoch 40,Minibatch 600] Average Training Loss : 0.355\n",
      "[Epoch 40,Minibatch 700] Average Training Loss : 0.351\n",
      "[Epoch 40] : Training Accuracy : 0.872 Test Accuracy 0.838\n",
      "[Epoch 41,Minibatch 100] Average Training Loss : 0.338\n",
      "[Epoch 41,Minibatch 200] Average Training Loss : 0.330\n",
      "[Epoch 41,Minibatch 300] Average Training Loss : 0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-482:\n",
      "Process Process-483:\n",
      "Process Process-481:\n",
      "Process Process-484:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-217ae9b12096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Epoch %d,Minibatch %d] Average Training Loss : %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "trains = []\n",
    "evals = []\n",
    "for epoch in range(300):\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    for i,data in enumerate(trainloader,1):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(densenet(inputs),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i%100==0:\n",
    "            print('[Epoch %d,Minibatch %d] Average Training Loss : %.3f' % (epoch+1,i,running_loss/100))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0\n",
    "            \n",
    "    trainaccuracy = check_accuracy(evalloader)\n",
    "    evalaccuracy = check_accuracy(testloader)\n",
    "    print('[Epoch %d] : Training Accuracy : %.3f Test Accuracy %.3f' % (epoch+1,trainaccuracy,evalaccuracy))\n",
    "    trains.append(trainaccuracy)\n",
    "    evals.append(evalaccuracy)\n",
    "\n",
    "print(\"TRAINING IS NOW COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trains,'r')\n",
    "plt.plot(evals,'b')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses,'b')\n",
    "plt.ylabel('Running Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(),'DenseNet40')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
