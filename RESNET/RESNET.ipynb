{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Data loading and augmentation\n",
    "#Try training without random rotation this time\n",
    "augmentations = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomCrop(32,padding=4),\n",
    "                                   transforms.ToTensor(),transforms.Normalize((0.0,0.0,0.0),(1.0,1.0,1.0))])\n",
    "test_tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.0,0.0,0.0),(1.0,1.0,1.0))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifardata',train=True,download=True,transform=augmentations)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifardata',train=False,download=True,transform=test_tf)\n",
    "trainval = torchvision.datasets.CIFAR10(root='./cifardata',train=True,download=True,transform=test_tf)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "evalloader = torch.utils.data.DataLoader(trainval,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID_Block(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ID_Block,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels,channels,3,padding=1,bias=False) #Bias terms are added by the batchnorm layer\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,3,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self,inchannels,outchannels):\n",
    "        super(Conv_Block,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inchannels,outchannels,3,stride=2,padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(outchannels)\n",
    "        self.conv2 = nn.Conv2d(outchannels,outchannels,3,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(outchannels)\n",
    "        self.conv_residual = nn.Conv2d(inchannels,outchannels,2,stride=2)\n",
    "        self.bn_residual = nn.BatchNorm2d(outchannels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = self.conv_residual(x)\n",
    "        residual = self.bn_residual(residual)\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,resblocks):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.resblocks = resblocks\n",
    "        self.global_avg_pool = nn.AvgPool2d(8,stride=1)\n",
    "        self.fc = nn.Linear(64,10)\n",
    "                \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.resblocks(out)\n",
    "        out = self.global_avg_pool(out)\n",
    "        out = out.view(-1,64)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resblocks = nn.Sequential(ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         ID_Block(16),\n",
    "                         Conv_Block(16,32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         ID_Block(32),\n",
    "                         Conv_Block(32,64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64),\n",
    "                         ID_Block(64))\n",
    "resnet = ResNet(resblocks)\n",
    "device = torch.device('cuda')\n",
    "resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(),lr=0.1,momentum=0.9,weight_decay=0.0001) #See https://arxiv.org/pdf/1705.08292.pdf\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones=[32000,48000])\n",
    "#optimizer = optim.Adam(resnet.parameters(),weight_decay=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return (correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1,Minibatch 1] Training Loss : 2.443\n",
      "[Epoch 1,Minibatch 2] Training Loss : 2.059\n",
      "[Epoch 1,Minibatch 3] Training Loss : 1.876\n",
      "[Epoch 1] : Training Accuracy : 0.370 Test Accuracy 0.378\n",
      "[Epoch 2,Minibatch 1] Training Loss : 3.301\n",
      "[Epoch 2,Minibatch 2] Training Loss : 1.620\n",
      "[Epoch 2,Minibatch 3] Training Loss : 1.545\n",
      "[Epoch 2] : Training Accuracy : 0.471 Test Accuracy 0.470\n",
      "[Epoch 3,Minibatch 1] Training Loss : 2.736\n",
      "[Epoch 3,Minibatch 2] Training Loss : 1.312\n",
      "[Epoch 3,Minibatch 3] Training Loss : 1.227\n",
      "[Epoch 3] : Training Accuracy : 0.600 Test Accuracy 0.592\n",
      "[Epoch 4,Minibatch 1] Training Loss : 2.149\n",
      "[Epoch 4,Minibatch 2] Training Loss : 0.991\n",
      "[Epoch 4,Minibatch 3] Training Loss : 0.983\n",
      "[Epoch 4] : Training Accuracy : 0.672 Test Accuracy 0.666\n",
      "[Epoch 5,Minibatch 1] Training Loss : 1.694\n",
      "[Epoch 5,Minibatch 2] Training Loss : 0.813\n",
      "[Epoch 5,Minibatch 3] Training Loss : 0.797\n",
      "[Epoch 5] : Training Accuracy : 0.744 Test Accuracy 0.727\n",
      "[Epoch 6,Minibatch 1] Training Loss : 1.390\n",
      "[Epoch 6,Minibatch 2] Training Loss : 0.711\n",
      "[Epoch 6,Minibatch 3] Training Loss : 0.690\n",
      "[Epoch 6] : Training Accuracy : 0.763 Test Accuracy 0.749\n",
      "[Epoch 7,Minibatch 1] Training Loss : 1.236\n",
      "[Epoch 7,Minibatch 2] Training Loss : 0.621\n",
      "[Epoch 7,Minibatch 3] Training Loss : 0.604\n",
      "[Epoch 7] : Training Accuracy : 0.794 Test Accuracy 0.784\n",
      "[Epoch 8,Minibatch 1] Training Loss : 1.137\n",
      "[Epoch 8,Minibatch 2] Training Loss : 0.565\n",
      "[Epoch 8,Minibatch 3] Training Loss : 0.552\n",
      "[Epoch 8] : Training Accuracy : 0.803 Test Accuracy 0.783\n",
      "[Epoch 9,Minibatch 1] Training Loss : 1.053\n",
      "[Epoch 9,Minibatch 2] Training Loss : 0.526\n",
      "[Epoch 9,Minibatch 3] Training Loss : 0.524\n",
      "[Epoch 9] : Training Accuracy : 0.820 Test Accuracy 0.796\n",
      "[Epoch 10,Minibatch 1] Training Loss : 0.959\n",
      "[Epoch 10,Minibatch 2] Training Loss : 0.472\n",
      "[Epoch 10,Minibatch 3] Training Loss : 0.493\n",
      "[Epoch 10] : Training Accuracy : 0.834 Test Accuracy 0.809\n",
      "[Epoch 11,Minibatch 1] Training Loss : 0.894\n",
      "[Epoch 11,Minibatch 2] Training Loss : 0.467\n",
      "[Epoch 11,Minibatch 3] Training Loss : 0.460\n",
      "[Epoch 11] : Training Accuracy : 0.845 Test Accuracy 0.819\n",
      "[Epoch 12,Minibatch 1] Training Loss : 0.850\n",
      "[Epoch 12,Minibatch 2] Training Loss : 0.429\n",
      "[Epoch 12,Minibatch 3] Training Loss : 0.439\n",
      "[Epoch 12] : Training Accuracy : 0.862 Test Accuracy 0.835\n",
      "[Epoch 13,Minibatch 1] Training Loss : 0.811\n",
      "[Epoch 13,Minibatch 2] Training Loss : 0.408\n",
      "[Epoch 13,Minibatch 3] Training Loss : 0.422\n",
      "[Epoch 13] : Training Accuracy : 0.859 Test Accuracy 0.832\n",
      "[Epoch 14,Minibatch 1] Training Loss : 0.754\n",
      "[Epoch 14,Minibatch 2] Training Loss : 0.403\n",
      "[Epoch 14,Minibatch 3] Training Loss : 0.401\n",
      "[Epoch 14] : Training Accuracy : 0.871 Test Accuracy 0.842\n",
      "[Epoch 15,Minibatch 1] Training Loss : 0.752\n",
      "[Epoch 15,Minibatch 2] Training Loss : 0.400\n",
      "[Epoch 15,Minibatch 3] Training Loss : 0.381\n",
      "[Epoch 15] : Training Accuracy : 0.871 Test Accuracy 0.841\n",
      "[Epoch 16,Minibatch 1] Training Loss : 0.693\n",
      "[Epoch 16,Minibatch 2] Training Loss : 0.366\n",
      "[Epoch 16,Minibatch 3] Training Loss : 0.379\n",
      "[Epoch 16] : Training Accuracy : 0.863 Test Accuracy 0.828\n",
      "[Epoch 17,Minibatch 1] Training Loss : 0.673\n",
      "[Epoch 17,Minibatch 2] Training Loss : 0.355\n",
      "[Epoch 17,Minibatch 3] Training Loss : 0.361\n",
      "[Epoch 17] : Training Accuracy : 0.879 Test Accuracy 0.846\n",
      "[Epoch 18,Minibatch 1] Training Loss : 0.655\n",
      "[Epoch 18,Minibatch 2] Training Loss : 0.335\n",
      "[Epoch 18,Minibatch 3] Training Loss : 0.355\n",
      "[Epoch 18] : Training Accuracy : 0.880 Test Accuracy 0.842\n",
      "[Epoch 19,Minibatch 1] Training Loss : 0.626\n",
      "[Epoch 19,Minibatch 2] Training Loss : 0.343\n",
      "[Epoch 19,Minibatch 3] Training Loss : 0.346\n",
      "[Epoch 19] : Training Accuracy : 0.880 Test Accuracy 0.844\n",
      "[Epoch 20,Minibatch 1] Training Loss : 0.602\n",
      "[Epoch 20,Minibatch 2] Training Loss : 0.312\n",
      "[Epoch 20,Minibatch 3] Training Loss : 0.324\n",
      "[Epoch 20] : Training Accuracy : 0.889 Test Accuracy 0.854\n",
      "[Epoch 21,Minibatch 1] Training Loss : 0.607\n",
      "[Epoch 21,Minibatch 2] Training Loss : 0.305\n",
      "[Epoch 21,Minibatch 3] Training Loss : 0.328\n",
      "[Epoch 21] : Training Accuracy : 0.880 Test Accuracy 0.846\n",
      "[Epoch 22,Minibatch 1] Training Loss : 0.588\n",
      "[Epoch 22,Minibatch 2] Training Loss : 0.289\n",
      "[Epoch 22,Minibatch 3] Training Loss : 0.313\n",
      "[Epoch 22] : Training Accuracy : 0.888 Test Accuracy 0.848\n",
      "[Epoch 23,Minibatch 1] Training Loss : 0.578\n",
      "[Epoch 23,Minibatch 2] Training Loss : 0.304\n",
      "[Epoch 23,Minibatch 3] Training Loss : 0.296\n",
      "[Epoch 23] : Training Accuracy : 0.894 Test Accuracy 0.853\n",
      "[Epoch 24,Minibatch 1] Training Loss : 0.537\n",
      "[Epoch 24,Minibatch 2] Training Loss : 0.292\n",
      "[Epoch 24,Minibatch 3] Training Loss : 0.307\n",
      "[Epoch 24] : Training Accuracy : 0.885 Test Accuracy 0.844\n",
      "[Epoch 25,Minibatch 1] Training Loss : 0.538\n",
      "[Epoch 25,Minibatch 2] Training Loss : 0.274\n",
      "[Epoch 25,Minibatch 3] Training Loss : 0.287\n",
      "[Epoch 25] : Training Accuracy : 0.891 Test Accuracy 0.852\n",
      "[Epoch 26,Minibatch 1] Training Loss : 0.539\n",
      "[Epoch 26,Minibatch 2] Training Loss : 0.263\n",
      "[Epoch 26,Minibatch 3] Training Loss : 0.272\n",
      "[Epoch 26] : Training Accuracy : 0.901 Test Accuracy 0.858\n",
      "[Epoch 27,Minibatch 1] Training Loss : 0.521\n",
      "[Epoch 27,Minibatch 2] Training Loss : 0.256\n",
      "[Epoch 27,Minibatch 3] Training Loss : 0.271\n",
      "[Epoch 27] : Training Accuracy : 0.899 Test Accuracy 0.854\n",
      "[Epoch 28,Minibatch 1] Training Loss : 0.525\n",
      "[Epoch 28,Minibatch 2] Training Loss : 0.267\n",
      "[Epoch 28,Minibatch 3] Training Loss : 0.263\n",
      "[Epoch 28] : Training Accuracy : 0.898 Test Accuracy 0.851\n",
      "[Epoch 29,Minibatch 1] Training Loss : 0.508\n",
      "[Epoch 29,Minibatch 2] Training Loss : 0.268\n",
      "[Epoch 29,Minibatch 3] Training Loss : 0.261\n",
      "[Epoch 29] : Training Accuracy : 0.908 Test Accuracy 0.860\n",
      "[Epoch 30,Minibatch 1] Training Loss : 0.473\n",
      "[Epoch 30,Minibatch 2] Training Loss : 0.257\n",
      "[Epoch 30,Minibatch 3] Training Loss : 0.245\n",
      "[Epoch 30] : Training Accuracy : 0.902 Test Accuracy 0.855\n",
      "[Epoch 31,Minibatch 1] Training Loss : 0.480\n",
      "[Epoch 31,Minibatch 2] Training Loss : 0.250\n",
      "[Epoch 31,Minibatch 3] Training Loss : 0.252\n",
      "[Epoch 31] : Training Accuracy : 0.905 Test Accuracy 0.857\n",
      "[Epoch 32,Minibatch 1] Training Loss : 0.475\n",
      "[Epoch 32,Minibatch 2] Training Loss : 0.235\n",
      "[Epoch 32,Minibatch 3] Training Loss : 0.254\n",
      "[Epoch 32] : Training Accuracy : 0.901 Test Accuracy 0.857\n",
      "[Epoch 33,Minibatch 1] Training Loss : 0.482\n",
      "[Epoch 33,Minibatch 2] Training Loss : 0.249\n",
      "[Epoch 33,Minibatch 3] Training Loss : 0.239\n",
      "[Epoch 33] : Training Accuracy : 0.901 Test Accuracy 0.857\n",
      "[Epoch 34,Minibatch 1] Training Loss : 0.451\n",
      "[Epoch 34,Minibatch 2] Training Loss : 0.230\n",
      "[Epoch 34,Minibatch 3] Training Loss : 0.240\n",
      "[Epoch 34] : Training Accuracy : 0.915 Test Accuracy 0.864\n",
      "[Epoch 35,Minibatch 1] Training Loss : 0.447\n",
      "[Epoch 35,Minibatch 2] Training Loss : 0.232\n",
      "[Epoch 35,Minibatch 3] Training Loss : 0.241\n",
      "[Epoch 35] : Training Accuracy : 0.916 Test Accuracy 0.866\n",
      "[Epoch 36,Minibatch 1] Training Loss : 0.429\n",
      "[Epoch 36,Minibatch 2] Training Loss : 0.229\n",
      "[Epoch 36,Minibatch 3] Training Loss : 0.243\n",
      "[Epoch 36] : Training Accuracy : 0.904 Test Accuracy 0.855\n",
      "[Epoch 37,Minibatch 1] Training Loss : 0.429\n",
      "[Epoch 37,Minibatch 2] Training Loss : 0.220\n",
      "[Epoch 37,Minibatch 3] Training Loss : 0.247\n",
      "[Epoch 37] : Training Accuracy : 0.913 Test Accuracy 0.868\n",
      "[Epoch 38,Minibatch 1] Training Loss : 0.423\n",
      "[Epoch 38,Minibatch 2] Training Loss : 0.218\n",
      "[Epoch 38,Minibatch 3] Training Loss : 0.221\n",
      "[Epoch 38] : Training Accuracy : 0.908 Test Accuracy 0.863\n",
      "[Epoch 39,Minibatch 1] Training Loss : 0.436\n",
      "[Epoch 39,Minibatch 2] Training Loss : 0.220\n",
      "[Epoch 39,Minibatch 3] Training Loss : 0.231\n",
      "[Epoch 39] : Training Accuracy : 0.910 Test Accuracy 0.861\n",
      "[Epoch 40,Minibatch 1] Training Loss : 0.410\n",
      "[Epoch 40,Minibatch 2] Training Loss : 0.227\n",
      "[Epoch 40,Minibatch 3] Training Loss : 0.216\n",
      "[Epoch 40] : Training Accuracy : 0.910 Test Accuracy 0.865\n",
      "[Epoch 41,Minibatch 1] Training Loss : 0.414\n",
      "[Epoch 41,Minibatch 2] Training Loss : 0.222\n",
      "[Epoch 41,Minibatch 3] Training Loss : 0.220\n",
      "[Epoch 41] : Training Accuracy : 0.913 Test Accuracy 0.860\n",
      "[Epoch 42,Minibatch 1] Training Loss : 0.413\n",
      "[Epoch 42,Minibatch 2] Training Loss : 0.222\n",
      "[Epoch 42,Minibatch 3] Training Loss : 0.216\n",
      "[Epoch 42] : Training Accuracy : 0.915 Test Accuracy 0.863\n",
      "[Epoch 43,Minibatch 1] Training Loss : 0.409\n",
      "[Epoch 43,Minibatch 2] Training Loss : 0.202\n",
      "[Epoch 43,Minibatch 3] Training Loss : 0.228\n",
      "[Epoch 43] : Training Accuracy : 0.918 Test Accuracy 0.868\n",
      "[Epoch 44,Minibatch 1] Training Loss : 0.408\n",
      "[Epoch 44,Minibatch 2] Training Loss : 0.200\n",
      "[Epoch 44,Minibatch 3] Training Loss : 0.223\n",
      "[Epoch 44] : Training Accuracy : 0.913 Test Accuracy 0.859\n",
      "[Epoch 45,Minibatch 1] Training Loss : 0.391\n",
      "[Epoch 45,Minibatch 2] Training Loss : 0.202\n",
      "[Epoch 45,Minibatch 3] Training Loss : 0.214\n",
      "[Epoch 45] : Training Accuracy : 0.911 Test Accuracy 0.865\n",
      "[Epoch 46,Minibatch 1] Training Loss : 0.392\n",
      "[Epoch 46,Minibatch 2] Training Loss : 0.188\n",
      "[Epoch 46,Minibatch 3] Training Loss : 0.216\n",
      "[Epoch 46] : Training Accuracy : 0.926 Test Accuracy 0.878\n",
      "[Epoch 47,Minibatch 1] Training Loss : 0.402\n",
      "[Epoch 47,Minibatch 2] Training Loss : 0.205\n",
      "[Epoch 47,Minibatch 3] Training Loss : 0.190\n",
      "[Epoch 47] : Training Accuracy : 0.909 Test Accuracy 0.864\n",
      "[Epoch 48,Minibatch 1] Training Loss : 0.393\n",
      "[Epoch 48,Minibatch 2] Training Loss : 0.196\n",
      "[Epoch 48,Minibatch 3] Training Loss : 0.203\n",
      "[Epoch 48] : Training Accuracy : 0.920 Test Accuracy 0.869\n",
      "[Epoch 49,Minibatch 1] Training Loss : 0.367\n",
      "[Epoch 49,Minibatch 2] Training Loss : 0.203\n",
      "[Epoch 49,Minibatch 3] Training Loss : 0.208\n",
      "[Epoch 49] : Training Accuracy : 0.910 Test Accuracy 0.862\n",
      "[Epoch 50,Minibatch 1] Training Loss : 0.378\n",
      "[Epoch 50,Minibatch 2] Training Loss : 0.186\n",
      "[Epoch 50,Minibatch 3] Training Loss : 0.218\n",
      "[Epoch 50] : Training Accuracy : 0.920 Test Accuracy 0.867\n",
      "[Epoch 51,Minibatch 1] Training Loss : 0.354\n",
      "[Epoch 51,Minibatch 2] Training Loss : 0.202\n",
      "[Epoch 51,Minibatch 3] Training Loss : 0.208\n",
      "[Epoch 51] : Training Accuracy : 0.917 Test Accuracy 0.863\n",
      "[Epoch 52,Minibatch 1] Training Loss : 0.373\n",
      "[Epoch 52,Minibatch 2] Training Loss : 0.192\n",
      "[Epoch 52,Minibatch 3] Training Loss : 0.219\n",
      "[Epoch 52] : Training Accuracy : 0.917 Test Accuracy 0.866\n",
      "[Epoch 53,Minibatch 1] Training Loss : 0.380\n",
      "[Epoch 53,Minibatch 2] Training Loss : 0.183\n",
      "[Epoch 53,Minibatch 3] Training Loss : 0.200\n",
      "[Epoch 53] : Training Accuracy : 0.917 Test Accuracy 0.864\n",
      "[Epoch 54,Minibatch 1] Training Loss : 0.368\n",
      "[Epoch 54,Minibatch 2] Training Loss : 0.195\n",
      "[Epoch 54,Minibatch 3] Training Loss : 0.204\n",
      "[Epoch 54] : Training Accuracy : 0.920 Test Accuracy 0.866\n",
      "[Epoch 55,Minibatch 1] Training Loss : 0.377\n",
      "[Epoch 55,Minibatch 2] Training Loss : 0.200\n",
      "[Epoch 55,Minibatch 3] Training Loss : 0.201\n",
      "[Epoch 55] : Training Accuracy : 0.926 Test Accuracy 0.873\n",
      "[Epoch 56,Minibatch 1] Training Loss : 0.358\n",
      "[Epoch 56,Minibatch 2] Training Loss : 0.179\n",
      "[Epoch 56,Minibatch 3] Training Loss : 0.188\n",
      "[Epoch 56] : Training Accuracy : 0.918 Test Accuracy 0.864\n",
      "[Epoch 57,Minibatch 1] Training Loss : 0.342\n",
      "[Epoch 57,Minibatch 2] Training Loss : 0.192\n",
      "[Epoch 57,Minibatch 3] Training Loss : 0.192\n",
      "[Epoch 57] : Training Accuracy : 0.918 Test Accuracy 0.868\n",
      "[Epoch 58,Minibatch 1] Training Loss : 0.354\n",
      "[Epoch 58,Minibatch 2] Training Loss : 0.175\n",
      "[Epoch 58,Minibatch 3] Training Loss : 0.194\n",
      "[Epoch 58] : Training Accuracy : 0.918 Test Accuracy 0.864\n",
      "[Epoch 59,Minibatch 1] Training Loss : 0.357\n",
      "[Epoch 59,Minibatch 2] Training Loss : 0.177\n",
      "[Epoch 59,Minibatch 3] Training Loss : 0.198\n",
      "[Epoch 59] : Training Accuracy : 0.915 Test Accuracy 0.859\n",
      "[Epoch 60,Minibatch 1] Training Loss : 0.356\n",
      "[Epoch 60,Minibatch 2] Training Loss : 0.174\n",
      "[Epoch 60,Minibatch 3] Training Loss : 0.190\n",
      "[Epoch 60] : Training Accuracy : 0.921 Test Accuracy 0.867\n",
      "[Epoch 61,Minibatch 1] Training Loss : 0.345\n",
      "[Epoch 61,Minibatch 2] Training Loss : 0.182\n",
      "[Epoch 61,Minibatch 3] Training Loss : 0.180\n",
      "[Epoch 61] : Training Accuracy : 0.916 Test Accuracy 0.860\n",
      "[Epoch 62,Minibatch 1] Training Loss : 0.349\n",
      "[Epoch 62,Minibatch 2] Training Loss : 0.170\n",
      "[Epoch 62,Minibatch 3] Training Loss : 0.189\n",
      "[Epoch 62] : Training Accuracy : 0.916 Test Accuracy 0.865\n",
      "[Epoch 63,Minibatch 1] Training Loss : 0.357\n",
      "[Epoch 63,Minibatch 2] Training Loss : 0.166\n",
      "[Epoch 63,Minibatch 3] Training Loss : 0.183\n",
      "[Epoch 63] : Training Accuracy : 0.926 Test Accuracy 0.871\n",
      "[Epoch 64,Minibatch 1] Training Loss : 0.331\n",
      "[Epoch 64,Minibatch 2] Training Loss : 0.178\n",
      "[Epoch 64,Minibatch 3] Training Loss : 0.176\n",
      "[Epoch 64] : Training Accuracy : 0.911 Test Accuracy 0.861\n",
      "[Epoch 65,Minibatch 1] Training Loss : 0.339\n",
      "[Epoch 65,Minibatch 2] Training Loss : 0.178\n",
      "[Epoch 65,Minibatch 3] Training Loss : 0.191\n",
      "[Epoch 65] : Training Accuracy : 0.915 Test Accuracy 0.861\n",
      "[Epoch 66,Minibatch 1] Training Loss : 0.341\n",
      "[Epoch 66,Minibatch 2] Training Loss : 0.183\n",
      "[Epoch 66,Minibatch 3] Training Loss : 0.185\n",
      "[Epoch 66] : Training Accuracy : 0.917 Test Accuracy 0.865\n",
      "[Epoch 67,Minibatch 1] Training Loss : 0.333\n",
      "[Epoch 67,Minibatch 2] Training Loss : 0.175\n",
      "[Epoch 67,Minibatch 3] Training Loss : 0.181\n",
      "[Epoch 67] : Training Accuracy : 0.917 Test Accuracy 0.865\n",
      "[Epoch 68,Minibatch 1] Training Loss : 0.331\n",
      "[Epoch 68,Minibatch 2] Training Loss : 0.188\n",
      "[Epoch 68,Minibatch 3] Training Loss : 0.183\n",
      "[Epoch 68] : Training Accuracy : 0.928 Test Accuracy 0.873\n",
      "[Epoch 69,Minibatch 1] Training Loss : 0.335\n",
      "[Epoch 69,Minibatch 2] Training Loss : 0.180\n",
      "[Epoch 69,Minibatch 3] Training Loss : 0.189\n",
      "[Epoch 69] : Training Accuracy : 0.922 Test Accuracy 0.862\n",
      "[Epoch 70,Minibatch 1] Training Loss : 0.324\n",
      "[Epoch 70,Minibatch 2] Training Loss : 0.184\n",
      "[Epoch 70,Minibatch 3] Training Loss : 0.182\n",
      "[Epoch 70] : Training Accuracy : 0.928 Test Accuracy 0.873\n",
      "[Epoch 71,Minibatch 1] Training Loss : 0.332\n",
      "[Epoch 71,Minibatch 2] Training Loss : 0.175\n",
      "[Epoch 71,Minibatch 3] Training Loss : 0.175\n",
      "[Epoch 71] : Training Accuracy : 0.917 Test Accuracy 0.866\n",
      "[Epoch 72,Minibatch 1] Training Loss : 0.342\n",
      "[Epoch 72,Minibatch 2] Training Loss : 0.177\n",
      "[Epoch 72,Minibatch 3] Training Loss : 0.186\n",
      "[Epoch 72] : Training Accuracy : 0.926 Test Accuracy 0.867\n",
      "[Epoch 73,Minibatch 1] Training Loss : 0.342\n",
      "[Epoch 73,Minibatch 2] Training Loss : 0.164\n",
      "[Epoch 73,Minibatch 3] Training Loss : 0.181\n",
      "[Epoch 73] : Training Accuracy : 0.915 Test Accuracy 0.864\n",
      "[Epoch 74,Minibatch 1] Training Loss : 0.322\n",
      "[Epoch 74,Minibatch 2] Training Loss : 0.167\n",
      "[Epoch 74,Minibatch 3] Training Loss : 0.170\n",
      "[Epoch 74] : Training Accuracy : 0.918 Test Accuracy 0.866\n",
      "[Epoch 75,Minibatch 1] Training Loss : 0.311\n",
      "[Epoch 75,Minibatch 2] Training Loss : 0.172\n",
      "[Epoch 75,Minibatch 3] Training Loss : 0.182\n",
      "[Epoch 75] : Training Accuracy : 0.920 Test Accuracy 0.865\n",
      "[Epoch 76,Minibatch 1] Training Loss : 0.305\n",
      "[Epoch 76,Minibatch 2] Training Loss : 0.169\n",
      "[Epoch 76,Minibatch 3] Training Loss : 0.172\n",
      "[Epoch 76] : Training Accuracy : 0.928 Test Accuracy 0.875\n",
      "[Epoch 77,Minibatch 1] Training Loss : 0.306\n",
      "[Epoch 77,Minibatch 2] Training Loss : 0.170\n",
      "[Epoch 77,Minibatch 3] Training Loss : 0.175\n",
      "[Epoch 77] : Training Accuracy : 0.924 Test Accuracy 0.871\n",
      "[Epoch 78,Minibatch 1] Training Loss : 0.308\n",
      "[Epoch 78,Minibatch 2] Training Loss : 0.162\n",
      "[Epoch 78,Minibatch 3] Training Loss : 0.165\n",
      "[Epoch 78] : Training Accuracy : 0.931 Test Accuracy 0.878\n",
      "[Epoch 79,Minibatch 1] Training Loss : 0.324\n",
      "[Epoch 79,Minibatch 2] Training Loss : 0.150\n",
      "[Epoch 79,Minibatch 3] Training Loss : 0.176\n",
      "[Epoch 79] : Training Accuracy : 0.923 Test Accuracy 0.867\n",
      "[Epoch 80,Minibatch 1] Training Loss : 0.328\n",
      "[Epoch 80,Minibatch 2] Training Loss : 0.167\n",
      "[Epoch 80,Minibatch 3] Training Loss : 0.172\n",
      "[Epoch 80] : Training Accuracy : 0.925 Test Accuracy 0.868\n",
      "[Epoch 81,Minibatch 1] Training Loss : 0.295\n",
      "[Epoch 81,Minibatch 2] Training Loss : 0.171\n",
      "[Epoch 81,Minibatch 3] Training Loss : 0.187\n",
      "[Epoch 81] : Training Accuracy : 0.922 Test Accuracy 0.866\n",
      "[Epoch 82,Minibatch 1] Training Loss : 0.325\n",
      "[Epoch 82,Minibatch 2] Training Loss : 0.166\n",
      "[Epoch 82,Minibatch 3] Training Loss : 0.174\n",
      "[Epoch 82] : Training Accuracy : 0.940 Test Accuracy 0.881\n",
      "[Epoch 83,Minibatch 1] Training Loss : 0.223\n",
      "[Epoch 83,Minibatch 2] Training Loss : 0.075\n",
      "[Epoch 83,Minibatch 3] Training Loss : 0.072\n",
      "[Epoch 83] : Training Accuracy : 0.956 Test Accuracy 0.892\n",
      "[Epoch 84,Minibatch 1] Training Loss : 0.119\n",
      "[Epoch 84,Minibatch 2] Training Loss : 0.059\n",
      "[Epoch 84,Minibatch 3] Training Loss : 0.060\n",
      "[Epoch 84] : Training Accuracy : 0.958 Test Accuracy 0.896\n",
      "[Epoch 85,Minibatch 1] Training Loss : 0.105\n",
      "[Epoch 85,Minibatch 2] Training Loss : 0.047\n",
      "[Epoch 85,Minibatch 3] Training Loss : 0.049\n",
      "[Epoch 85] : Training Accuracy : 0.960 Test Accuracy 0.896\n",
      "[Epoch 86,Minibatch 1] Training Loss : 0.084\n",
      "[Epoch 86,Minibatch 2] Training Loss : 0.045\n",
      "[Epoch 86,Minibatch 3] Training Loss : 0.043\n",
      "[Epoch 86] : Training Accuracy : 0.962 Test Accuracy 0.895\n",
      "[Epoch 87,Minibatch 1] Training Loss : 0.073\n",
      "[Epoch 87,Minibatch 2] Training Loss : 0.040\n",
      "[Epoch 87,Minibatch 3] Training Loss : 0.037\n",
      "[Epoch 87] : Training Accuracy : 0.962 Test Accuracy 0.895\n",
      "[Epoch 88,Minibatch 1] Training Loss : 0.071\n",
      "[Epoch 88,Minibatch 2] Training Loss : 0.034\n",
      "[Epoch 88,Minibatch 3] Training Loss : 0.032\n",
      "[Epoch 88] : Training Accuracy : 0.965 Test Accuracy 0.897\n",
      "[Epoch 89,Minibatch 1] Training Loss : 0.062\n",
      "[Epoch 89,Minibatch 2] Training Loss : 0.033\n",
      "[Epoch 89,Minibatch 3] Training Loss : 0.029\n",
      "[Epoch 89] : Training Accuracy : 0.967 Test Accuracy 0.899\n",
      "[Epoch 90,Minibatch 1] Training Loss : 0.057\n",
      "[Epoch 90,Minibatch 2] Training Loss : 0.026\n",
      "[Epoch 90,Minibatch 3] Training Loss : 0.032\n",
      "[Epoch 90] : Training Accuracy : 0.969 Test Accuracy 0.900\n",
      "[Epoch 91,Minibatch 1] Training Loss : 0.052\n",
      "[Epoch 91,Minibatch 2] Training Loss : 0.028\n",
      "[Epoch 91,Minibatch 3] Training Loss : 0.029\n",
      "[Epoch 91] : Training Accuracy : 0.967 Test Accuracy 0.897\n",
      "[Epoch 92,Minibatch 1] Training Loss : 0.048\n",
      "[Epoch 92,Minibatch 2] Training Loss : 0.026\n",
      "[Epoch 92,Minibatch 3] Training Loss : 0.023\n",
      "[Epoch 92] : Training Accuracy : 0.969 Test Accuracy 0.899\n",
      "[Epoch 93,Minibatch 1] Training Loss : 0.047\n",
      "[Epoch 93,Minibatch 2] Training Loss : 0.025\n",
      "[Epoch 93,Minibatch 3] Training Loss : 0.025\n",
      "[Epoch 93] : Training Accuracy : 0.970 Test Accuracy 0.900\n",
      "[Epoch 94,Minibatch 1] Training Loss : 0.040\n",
      "[Epoch 94,Minibatch 2] Training Loss : 0.021\n",
      "[Epoch 94,Minibatch 3] Training Loss : 0.021\n",
      "[Epoch 94] : Training Accuracy : 0.971 Test Accuracy 0.899\n",
      "[Epoch 95,Minibatch 1] Training Loss : 0.043\n",
      "[Epoch 95,Minibatch 2] Training Loss : 0.020\n",
      "[Epoch 95,Minibatch 3] Training Loss : 0.024\n",
      "[Epoch 95] : Training Accuracy : 0.967 Test Accuracy 0.896\n",
      "[Epoch 96,Minibatch 1] Training Loss : 0.041\n",
      "[Epoch 96,Minibatch 2] Training Loss : 0.021\n",
      "[Epoch 96,Minibatch 3] Training Loss : 0.019\n",
      "[Epoch 96] : Training Accuracy : 0.969 Test Accuracy 0.898\n",
      "[Epoch 97,Minibatch 1] Training Loss : 0.035\n",
      "[Epoch 97,Minibatch 2] Training Loss : 0.019\n",
      "[Epoch 97,Minibatch 3] Training Loss : 0.018\n",
      "[Epoch 97] : Training Accuracy : 0.970 Test Accuracy 0.899\n",
      "[Epoch 98,Minibatch 1] Training Loss : 0.032\n",
      "[Epoch 98,Minibatch 2] Training Loss : 0.018\n",
      "[Epoch 98,Minibatch 3] Training Loss : 0.021\n",
      "[Epoch 98] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 99,Minibatch 1] Training Loss : 0.033\n",
      "[Epoch 99,Minibatch 2] Training Loss : 0.017\n",
      "[Epoch 99,Minibatch 3] Training Loss : 0.018\n",
      "[Epoch 99] : Training Accuracy : 0.971 Test Accuracy 0.898\n",
      "[Epoch 100,Minibatch 1] Training Loss : 0.031\n",
      "[Epoch 100,Minibatch 2] Training Loss : 0.018\n",
      "[Epoch 100,Minibatch 3] Training Loss : 0.016\n",
      "[Epoch 100] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 101,Minibatch 1] Training Loss : 0.030\n",
      "[Epoch 101,Minibatch 2] Training Loss : 0.017\n",
      "[Epoch 101,Minibatch 3] Training Loss : 0.018\n",
      "[Epoch 101] : Training Accuracy : 0.968 Test Accuracy 0.897\n",
      "[Epoch 102,Minibatch 1] Training Loss : 0.030\n",
      "[Epoch 102,Minibatch 2] Training Loss : 0.017\n",
      "[Epoch 102,Minibatch 3] Training Loss : 0.015\n",
      "[Epoch 102] : Training Accuracy : 0.970 Test Accuracy 0.899\n",
      "[Epoch 103,Minibatch 1] Training Loss : 0.027\n",
      "[Epoch 103,Minibatch 2] Training Loss : 0.013\n",
      "[Epoch 103,Minibatch 3] Training Loss : 0.013\n",
      "[Epoch 103] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 104,Minibatch 1] Training Loss : 0.028\n",
      "[Epoch 104,Minibatch 2] Training Loss : 0.015\n",
      "[Epoch 104,Minibatch 3] Training Loss : 0.015\n",
      "[Epoch 104] : Training Accuracy : 0.969 Test Accuracy 0.898\n",
      "[Epoch 105,Minibatch 1] Training Loss : 0.025\n",
      "[Epoch 105,Minibatch 2] Training Loss : 0.014\n",
      "[Epoch 105,Minibatch 3] Training Loss : 0.014\n",
      "[Epoch 105] : Training Accuracy : 0.970 Test Accuracy 0.897\n",
      "[Epoch 106,Minibatch 1] Training Loss : 0.026\n",
      "[Epoch 106,Minibatch 2] Training Loss : 0.013\n",
      "[Epoch 106,Minibatch 3] Training Loss : 0.013\n",
      "[Epoch 106] : Training Accuracy : 0.969 Test Accuracy 0.897\n",
      "[Epoch 107,Minibatch 1] Training Loss : 0.025\n",
      "[Epoch 107,Minibatch 2] Training Loss : 0.011\n",
      "[Epoch 107,Minibatch 3] Training Loss : 0.015\n",
      "[Epoch 107] : Training Accuracy : 0.970 Test Accuracy 0.897\n",
      "[Epoch 108,Minibatch 1] Training Loss : 0.023\n",
      "[Epoch 108,Minibatch 2] Training Loss : 0.011\n",
      "[Epoch 108,Minibatch 3] Training Loss : 0.013\n",
      "[Epoch 108] : Training Accuracy : 0.971 Test Accuracy 0.898\n",
      "[Epoch 109,Minibatch 1] Training Loss : 0.021\n",
      "[Epoch 109,Minibatch 2] Training Loss : 0.009\n",
      "[Epoch 109,Minibatch 3] Training Loss : 0.010\n",
      "[Epoch 109] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 110,Minibatch 1] Training Loss : 0.021\n",
      "[Epoch 110,Minibatch 2] Training Loss : 0.012\n",
      "[Epoch 110,Minibatch 3] Training Loss : 0.011\n",
      "[Epoch 110] : Training Accuracy : 0.972 Test Accuracy 0.900\n",
      "[Epoch 111,Minibatch 1] Training Loss : 0.020\n",
      "[Epoch 111,Minibatch 2] Training Loss : 0.009\n",
      "[Epoch 111,Minibatch 3] Training Loss : 0.010\n",
      "[Epoch 111] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 112,Minibatch 1] Training Loss : 0.017\n",
      "[Epoch 112,Minibatch 2] Training Loss : 0.010\n",
      "[Epoch 112,Minibatch 3] Training Loss : 0.010\n",
      "[Epoch 112] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 113,Minibatch 1] Training Loss : 0.018\n",
      "[Epoch 113,Minibatch 2] Training Loss : 0.011\n",
      "[Epoch 113,Minibatch 3] Training Loss : 0.011\n",
      "[Epoch 113] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 114,Minibatch 1] Training Loss : 0.021\n",
      "[Epoch 114,Minibatch 2] Training Loss : 0.010\n",
      "[Epoch 114,Minibatch 3] Training Loss : 0.010\n",
      "[Epoch 114] : Training Accuracy : 0.970 Test Accuracy 0.898\n",
      "[Epoch 115,Minibatch 1] Training Loss : 0.017\n",
      "[Epoch 115,Minibatch 2] Training Loss : 0.010\n",
      "[Epoch 115,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 115] : Training Accuracy : 0.970 Test Accuracy 0.900\n",
      "[Epoch 116,Minibatch 1] Training Loss : 0.018\n",
      "[Epoch 116,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 116,Minibatch 3] Training Loss : 0.010\n",
      "[Epoch 116] : Training Accuracy : 0.973 Test Accuracy 0.900\n",
      "[Epoch 117,Minibatch 1] Training Loss : 0.017\n",
      "[Epoch 117,Minibatch 2] Training Loss : 0.007\n",
      "[Epoch 117,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 117] : Training Accuracy : 0.971 Test Accuracy 0.898\n",
      "[Epoch 118,Minibatch 1] Training Loss : 0.014\n",
      "[Epoch 118,Minibatch 2] Training Loss : 0.009\n",
      "[Epoch 118,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 118] : Training Accuracy : 0.970 Test Accuracy 0.897\n",
      "[Epoch 119,Minibatch 1] Training Loss : 0.015\n",
      "[Epoch 119,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 119,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 119] : Training Accuracy : 0.970 Test Accuracy 0.900\n",
      "[Epoch 120,Minibatch 1] Training Loss : 0.016\n",
      "[Epoch 120,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 120,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 120] : Training Accuracy : 0.969 Test Accuracy 0.896\n",
      "[Epoch 121,Minibatch 1] Training Loss : 0.017\n",
      "[Epoch 121,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 121,Minibatch 3] Training Loss : 0.007\n",
      "[Epoch 121] : Training Accuracy : 0.969 Test Accuracy 0.896\n",
      "[Epoch 122,Minibatch 1] Training Loss : 0.016\n",
      "[Epoch 122,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 122,Minibatch 3] Training Loss : 0.009\n",
      "[Epoch 122] : Training Accuracy : 0.969 Test Accuracy 0.895\n",
      "[Epoch 123,Minibatch 1] Training Loss : 0.014\n",
      "[Epoch 123,Minibatch 2] Training Loss : 0.008\n",
      "[Epoch 123,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 123] : Training Accuracy : 0.970 Test Accuracy 0.895\n",
      "[Epoch 124,Minibatch 1] Training Loss : 0.014\n",
      "[Epoch 124,Minibatch 2] Training Loss : 0.007\n",
      "[Epoch 124,Minibatch 3] Training Loss : 0.008\n",
      "[Epoch 124] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 125,Minibatch 1] Training Loss : 0.012\n",
      "[Epoch 125,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 125,Minibatch 3] Training Loss : 0.007\n",
      "[Epoch 125] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 126,Minibatch 1] Training Loss : 0.014\n",
      "[Epoch 126,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 126,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 126] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 127,Minibatch 1] Training Loss : 0.012\n",
      "[Epoch 127,Minibatch 2] Training Loss : 0.007\n",
      "[Epoch 127,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 127] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 128,Minibatch 1] Training Loss : 0.013\n",
      "[Epoch 128,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 128,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 128] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 129,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 129,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 129,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 129] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 130,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 130,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 130,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 130] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 131,Minibatch 1] Training Loss : 0.012\n",
      "[Epoch 131,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 131,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 131] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 132,Minibatch 1] Training Loss : 0.011\n",
      "[Epoch 132,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 132,Minibatch 3] Training Loss : 0.007\n",
      "[Epoch 132] : Training Accuracy : 0.971 Test Accuracy 0.897\n",
      "[Epoch 133,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 133,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 133,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 133] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 134,Minibatch 1] Training Loss : 0.012\n",
      "[Epoch 134,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 134,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 134] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 135,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 135,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 135,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 135] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 136,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 136,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 136,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 136] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 137,Minibatch 1] Training Loss : 0.011\n",
      "[Epoch 137,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 137,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 137] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 138,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 138,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 138,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 138] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 139,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 139,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 139,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 139] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 140,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 140,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 140,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 140] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 141,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 141,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 141,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 141] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 142,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 142,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 142,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 142] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 143,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 143,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 143,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 143] : Training Accuracy : 0.973 Test Accuracy 0.899\n",
      "[Epoch 144,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 144,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 144,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 144] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 145,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 145,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 145,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 145] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 146,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 146,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 146,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 146] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 147,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 147,Minibatch 2] Training Loss : 0.006\n",
      "[Epoch 147,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 147] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 148,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 148,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 148,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 148] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 149,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 149,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 149,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 149] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 150,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 150,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 150,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 150] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 151,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 151,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 151,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 151] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 152,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 152,Minibatch 2] Training Loss : 0.004\n",
      "[Epoch 152,Minibatch 3] Training Loss : 0.006\n",
      "[Epoch 152] : Training Accuracy : 0.972 Test Accuracy 0.897\n",
      "[Epoch 153,Minibatch 1] Training Loss : 0.011\n",
      "[Epoch 153,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 153,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 153] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 154,Minibatch 1] Training Loss : 0.010\n",
      "[Epoch 154,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 154,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 154] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 155,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 155,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 155,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 155] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 156,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 156,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 156,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 156] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 157,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 157,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 157,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 157] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 158,Minibatch 1] Training Loss : 0.008\n",
      "[Epoch 158,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 158,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 158] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 159,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 159,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 159,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 159] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 160,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 160,Minibatch 2] Training Loss : 0.004\n",
      "[Epoch 160,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 160] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 161,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 161,Minibatch 2] Training Loss : 0.004\n",
      "[Epoch 161,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 161] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 162,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 162,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 162,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 162] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "[Epoch 163,Minibatch 1] Training Loss : 0.009\n",
      "[Epoch 163,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 163,Minibatch 3] Training Loss : 0.005\n",
      "[Epoch 163] : Training Accuracy : 0.972 Test Accuracy 0.899\n",
      "[Epoch 164,Minibatch 1] Training Loss : 0.008\n",
      "[Epoch 164,Minibatch 2] Training Loss : 0.005\n",
      "[Epoch 164,Minibatch 3] Training Loss : 0.004\n",
      "[Epoch 164] : Training Accuracy : 0.972 Test Accuracy 0.898\n",
      "TRAINING IS NOW COMPLETE\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "eval_losses = []\n",
    "trains = []\n",
    "evals = []\n",
    "iters = 0\n",
    "i = 0\n",
    "epochs = 0\n",
    "running_loss = 0\n",
    "running_val_loss = 0\n",
    "while iters < 64000:\n",
    "    epochs += 1\n",
    "    i = 0\n",
    "    for i,data in enumerate(trainloader,1):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i%100==0:\n",
    "            print('[Epoch %d,Minibatch %d] Training Loss : %.3f' % (epochs,i/100,running_loss/100))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0\n",
    "            running_val_loss = 0\n",
    "        iters += 1\n",
    "        \n",
    "    trainaccuracy = check_accuracy(evalloader)\n",
    "    evalaccuracy = check_accuracy(testloader)\n",
    "    print('[Epoch %d] : Training Accuracy : %.3f Test Accuracy %.3f' % (epochs,trainaccuracy,evalaccuracy))\n",
    "    trains.append(trainaccuracy)\n",
    "    evals.append(evalaccuracy)\n",
    "\n",
    "print(\"TRAINING IS NOW COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8VOW59//PlYSQQIAACQcFBC0qWrUqHmvd9YyWymN9rGirtba1tlWrtfbRdj/qz/3bduu2W621VuvZWpVqq2y11VZ72tVa8SwiSkEEFEiAACEccrieP66ZZIghGQ4za8J836/XvDJrzZq1rlkzua9132ut+zZ3R0REBKAk6QBERKRwKCmIiEg7JQUREWmnpCAiIu2UFEREpJ2SgoiItFNSEBGRdjlLCmZ2p5ktNbM3N/G6mdmPzWyOmb1uZvvlKhYREclOLmsKdwOTunn9eGB86nEOcEsOYxERkSyU5WrF7v4XMxvbzSJTgHs9bqn+u5lVm9lId/+wu/XW1NT42LHdrVZERDp76aWX6t29tqflcpYUsrAjsCBjemFq3keSgpmdQ9QmGDNmDDNmzMhLgCIi2wszm5/Ncr3iRLO73+buE919Ym1tj4lORES2UJJJYREwOmN6VGqeiIgkJMmkMB04M3UV0sHAyp7OJ4iISG7l7JyCmT0AfBqoMbOFwBVAHwB3/xnwJHACMAdoAr6cq1hERCQ7ubz66LQeXnfgW7navoiIbL5ecaJZRETyQ0lBRETaJXmfgojkw6JFUFsL5eU9L9vaCu+/D3PmwO67w+jR3S+/YQM8+iisXAnHHQdjxmx9vK2tsGZN/AVwjwdAWxu0tEBJCfTvD2bQ3BxxpOeXlsK6dbB2bTzWr491ZT7a2qBfP6iujm3V10NdXXyOsjLo2zf2V9++XT9va4vtZj5aWmLbpaWxjvRfs47P0PkBsUz60dwMy5ZBU1O8ZrbxY7/9YOedt34fd0NJQSRJy5fDP/4BhxwCgwbBe+/Bc89FIbVgAcyeDRMmwGWXRWH0u9/B3LmwZEk8Fi+Ovy0tcPDB8C//AocfHuv95S/hsceigB81Ci64IArPd9+NgmXUKJg3D+bPj4JowQJ4550oRCEK2BNOgL33jgJ4w4aOgrapKQrQv/0NPsy4aHDs2Fi+qipiGj0axo+HAQOgoiIK1YYGeP55+Oc/YfVqaGzc+O/atUl8E73DLbfAuefmdBPm6WzVS0ycONF1R7P0auvXw5NPwn33wRNPRGFbURFH5q++2rFc375ReL/9NgwZEsutXh2vVVTA8OEwYkT8bW2NZLJiRcf7+/SBo46CI46Axx+Hv/415o8cGcnEPY5mR42CmpqYv9tu8dh5Z3j2Wbj33ij000ftFRVQWRlH2QMHwi67wDe+Ecngd7+LBPf66xFraWnUOtat++g+qKqKZDdwYDwfMKDj74ABkYRKS2NZs46/ZvG50rUJ90iWffrEkbZ7JKN0nOlElD5yTz9KSiKxrVgR26qpidpUdXW8f8OG+J7Wr+/6eUlJbDP9KC+P9WbWRlpa4pHW+ag//bkyly0tjVj69YvXOtcsdtgBhg7dop+dmb3k7hN7XE5JQSRP6urg1lvhxhujJjB8OJx2WhTcv/sdvPIKTJ4cjxEjIhGUlkaiuOqqqEmceWY0IQwc2FGopLW1wZtvwl/+EgXhySfHOtLefReGDYv1rFkTiWH06J6bldyjWaOsLArDzdHaCh98EAXw+vWRICoqYI89Yn2SN0oKIklyh1mz4Le/jccrr0STDkSTzHnnwTHHqGCUvMk2KegXKbItNTbCTTdFjWB+qv+xPfeEU06JppZjj4V99kk2RpFuKCmIbCtvvRXt90uXRuH//e/DpEnb5oockTxRUhDZVm68MWoKzz8fVwKJ9EK6eU1kW1i/HqZNg5NOUkKQXk1JQWRbeOKJuP7+jDOSjkRkqygpiGwL990Xl5EedVTSkYhsFSUFka21fHnUFE4/XZeYSq+npCCytR57LG7uOv30pCMR2WpKCiJb65FHopuH/fZLOhKRraakIJKNG26ASy7p6NkybdUq+P3v4XOf+2i3EyK9kJKCbBn3uCZ/a6xbF30AbYmGhugdtDt//3tcHvraaxHvVVfBl7/cUbC3tn60kE974gn41Kfg5Zejeeiii+C66+CnP/3ochs2RFIQ2Q7orJhsmdtug+9+N7o/HjZs89+/Zk108zxvXnT41lO//Zna2uKO4VWron+hro7Q3SO+F16Ao4+GKVPgjjvitVNOiW0fcgh8+tPw4x9v/N7334cvfjESzyc/Gb1gTpwYn/M734lk9OabsNde0SvoyJGxLpHtgbv3qsf+++/vkrC2Nve9947OfG++OeY1N7uvXduxzLx57qtWdf3+lhb3KVPcS0rc+/Vz/9Sn4v1dee8994sucv/gg455997b0Znw//xP1+/7/e/j9e9+133kyHh+7rnu48a577+/+7e/HfPM3F97reN9q1a5H3aYe1WV+3PPuX/60+61tfF56uvdR4+O940d2xHDN7+Z7Z4TSQwww7MoYxMv5Df3oaSQZ6tXu99wg/vMmR3zXn65o0A9/PBIEpMmue+zj/uGDe4LFrhXVkZhPG2ae12d+/LlUeC+8IL7kUfG+3/8444C/l/+xf3006OAveoq9xkzIhHssku8/rGPuc+f775mjfuOO7p/4hORUM45Z+N4P/zQfdYs90MPdR81yn3dOvc5c9zvvNO9tTX+pgvzM85wHzw4Yn/jDffTTnOvqIjXfvGLWF9b28bJbtky98WL4/mbb7pfcon73Lk5/QpEtgUlBQn33uv+hS+4n3CC+9NPd8xva+v+fUuXut91VxSs4N6/v/sjj8RrF1zgXl4eR9tmGxe0t9zi/tWvxuv77NMxP/NRU+P+0592bOv733fffXf3nXeOQjq93IABsd2bb3YfNCiO3tOv/+UvUagPGuTe1OT+8MPuRxyx8XYyt5HW3Oy+667uY8ZEkrruuo4EN3BgJKW//32rd7tIoVFSkDiq7ds3mj+qq90nTIij5eeei4I53fST1tbm/swzcdSeLlj32cf90UfdDzoopqdMcR861P3zn48jcnAvK4vmlMMOcx8yJJqFvv3tKIAffND9ppvcr78+CuBbbnFfubL7uBsa3G+8MZqVnn025r36qvvXvub+9a9HsnJ3/8MfYvsTJsTfcePc/+3f3B94wH369Gim6srSpVF7cY9awOTJ7hdfHM1DItupgkgKwCRgNjAHuLSL13cCngFeB/4EjOppnUoKKW1t7n/7WzSPbMoNN8RX/OqrUVCC+69+5b7vvnFkDNFkcuCBUbCXlsa8HXeMJpwXXugoWNetc7/yyo4j9d/+Nuanzy3ce28sD3FEv3Rp7vdBS4v7TjtFM9INN2w6CYhI1kkhZyOvmVkp8A5wDLAQeBE4zd3fyljmV8Dj7n6PmR0JfNndu+1RTCOvpfzyl/CFL8BnPgO//nWM77psWcdVPO4xuMuAAXEFTmtrjAG8ZEmM8/uLX8Sg6z/7Wdx0deSRcZXNuHFx5U1FRdfbbWyMUcQOOyyu+rn/fnj0UXjwwRg68kc/ivEDTjklP/vh/feja4kddsjP9kR6qWxHXstlLeEQ4KmM6cuAyzotMxMYnXpuwKqe1luUNYXm5o2Pghsbo60/fVXNAQd0HMFfdlks+9e/xvQdd3S87+c/j3mHHdZxTqG7moaIbDfIsqaQy/sUdgQWZEwvBA7qtMxrwOeAG4GTgAFmNtTdl+Uwrt7FPXrefOcduOCCuD7/oYdg4cIYoP211+Dii+HEE6FfP/jhD+PoffXqGNz91FM71nXGGXF9/bnndlzb37dvMp+ryLnDnDlxi8aiRVHhGz8eVqyAP/8Z/vjHuCfumGPiMWBAvG/p0qjsrVsHu+0WX3F6fatXR2Wtf/+Yt3AhlJTEbRQ93WydPolUUhLrv/9+GDwYPvtZGDo0unbq0yeWbWqKCtqLL3aMODp8eNz6seuusa158+Dpp+PnOm7c5u2blpa4/WX06PhJbwutrdFvYX197LuSkniUlkZFs6QkPteaNR3z+vTZ+G9ZGdTWZv8v4x6fpbU1HpnP166Nf8V334Xq6viOdtstPrN7LNPWFr+HDz6I/bDjjh3fdy7lsvnofwOT3P2rqekzgIPc/byMZXYAfgKMA/4CnAx83N0bOq3rHOAcgDFjxuw/P/1LLAaPPhoDt+y5J8yc2TH/1FOjyQbiF1RaGs/vuw9+85v4jz7hBDj55PzHXORaWqKFbeHCKEgOPxwGDYr5f/sbTJ8eN0n/858bv+9jH4t57lBZGe9dvToKhJNPhgUL4E9/6ljeLFrqmpqiwGttjcJtr71izJ+3347lBg+GIUOgvDzuvxs2LArGtWvjZ9PYGAXU2rXRhdO8eZEEMreTLibKyuJzbEplZfQgPm9eTPftCxdeGHGWlsJBB8Hee0ecM2bAz3++8X5obo59l05wEybE+iB+/itWREvhkCGx7vLy+Jt+lJdHjCtWRAKoq4u/K1Zs+ub1zVFSEvuooqIjuXROHhs2RLJcsWLrt9fZTTfBeef1vFxXsm0+ymVSOAS40t2PS01fBuDuP9zE8lXA2+4+qrv1btfnFBYvhqeeijb90tL4L99nn/hPmTkzDi1nz4aVK2Hy5PjPkILy9NNRCM6a1TGvpCSOBhsa4uivvDxO4Xz2s9ELx5AhcWT+3HNw4IHx2oEHxvueey5O/zz4YBxNfvGLsMceUfi88Ub8HAYMiHUMGRI/jeefj5/PscdGQTVzZhSy69dHLWDp0kg0lZXxE6uogI9/HKqqOo7Qzz03jpp/+9t4X9++Udg1N8dnGTEibvIePz6Sxty5UcN5++1IhvvsE9v/0Y86jl0y94dZbLtfP/jEJzpqMmYRy8SJkVheey1OlTU3x+eurY0j54aGiGv9+ogr83lzcyTC2lqoqYlH5vPKyvge0kft6Ue/flHLamuLdbS0bPy3uTlqdbNnx/OKio7aQOaypaWw006xzT59Yjpd+0g/Ly+PmsHuu8d3s3Bh7LvFiztqMSUlcTCxww6R+BctilrjJz6xZb/NQkgKZcSJ5qOARcSJ5tPdfWbGMjXAcndvM7N/B1rd/fLu1rvdJIW2tvjW0+bMiW/8vfei24Xzz4d77oGzzormos9/PqlIJUsPPQRTp8Iuu8AVV0TlbvVqeOaZKNgGD47CctKkjuagbKX/TXtjn3tLl0b8TU1RU0onzDFjYn8NGpRsfMUi8aSQCuIE4AagFLjT3f/dzK4iTnhMTzUx/RBwovnoW+6+vrt1bhdJYfnyOBT88pfhBz+IQ6KDD47DlfHj4xDwllvg61+PtoDnn984gUjBaWmJpo5+/aI7JJ2qkUJTEEkhF7aLpPCtb0Vvm2VlUT/+1reiN84XXoi67Z57Rt19jz3ijOOWdDgneXX33ZHjH300+t4TKTTZJgX1kpovy5ZFW8Ly5XFvwBe+EN0uH3FE1K9vvz0aGCFqCXfdFfciKCEUvObm6JV7v/3iIjCR3kxtErn2/PPRNFRbG9fm7b9/nBG86Sa4+upICMcdB2ef3fGeM86AZ5/tuOyiAC1ZEkfHvayiucX+8Y84idyV6dOjBfCKK3pnm79IJtUUcu3ii+Pk8RVXxGUEc+ZEEhg8GM45Jy5hmDy515UmP/hBDE+w665w6KFJR7PtLVsG//3fUaFbsCCGZGhpia+yc+Xtnnviq/3MZxIJVWTbyuYOt0J6FPQdzYsWRRfR6buF58yJe4KuuSbZuLax+vqOHqbPOmvL1/PjH0fP1z112NqV1as7+rTblHffdb/00uht2939scfcf/CD6BOwJ6ed5u09eh9wQHTYahbry7RkSXQb9b3vbf5nEMknCqFDvFw8CjYpPPdcRydzI0a4v/JKdCBn5v7++0lH9xGbUxB37mfuP/4jPubhh0dfdA0N7m+/Hf3uZeuxx9L30HZ0erpwYRT2Pamri+EVxo7deKiDTGvWuO+5Z0dOXr06OouF+Fq6M2NGLHfMMR3Jb9o091NPjeSQmffTfQ6++WbWH10kEUoK+Xb88dGl9HXXue+wg/v48TE+wBFHJB2Zz53rfvXVMY6Me+Sr2too0HpKDs8+Gx/rP/4jppubY/CxI4/s6BT19NMjOVRWxlAEixe7n3KK+7XXxlF5Q4P7Qw9FHK2tMSjawIExANqhh0Zv29deG71877zzxgOhvfhi7MJZs2K6qcn9kEPc+/SJbV933cbxNjdHDj7jjMjHEybE+i+7rOPIH2KIiQMOcD/77EhG//hHHO3ffXcMtjZ0aMSd7mDWPeKCGIqhvDzWPXp0fA6RQqekkA/Ll0cp9dJLsSv//d9j/p//HGMKdO6QLs9aW6N5J12BOfTQSAKnn95xlP6Vr0T4zz8fhe9ee8XAai0t7vfdF4Vfnz7RRPLKK9H8Au6/+c3Go3Lut18U6DU1UWimP35mX30QBXS6MvXee3GEXVYW844+OvJpZaX7/ffHGDg77xyv7bVXNFtNmhSf55FH3I87Lta3YkV8DVdfHckmva3LL+846ocYZ2jt2tgP/fvHcA3l5R09hqf3E0TC7MrFF7sfdZT7hRdGTQmin0GRQqekkGsbNkQJVlPj/vGPxwhgDQ0dr//oR9HGkTlvG2ptdX/iie6bW668Mr7hCy6IAhKisC0rcz///GgfzxyobNiw6Hi1T58YUgHiqPzdd6MQTxfuZ5/dUcN4+mn3886LON55J46wR42KwviOO6K55TOfieWuvTYS0v33d7Tzu8f0LbfEZ/rwwyisIQZIKynp+BzV1VFwp/NselTQkSOjkAf3E090/9nPYvyddIyf+1y89uKLHfsu3SQ2d24U8DfdFF/VSy9Fc9aGDdl9D6tWbdk5EZF8U1LItaefjt2XPlTuqqF6G5QWbW3uV1wRQwFnDlj2k594+5F4XV1UTq68Mk7e3nFHvAfczzwz1tHUFAV7nz5RsL77bqxn0aKoEdx0UxRw9fXuX/pSFOS/+pX7+vWxXPocwNlnd3+idsmSjePM5qRuZxs2xMBtmbv10ksjmT344MbLXn11FPoXXOD+pz9tOqYnntj8OES2J0oKuXbOOTHCWFNTDFS/GaVfW1tUJF5+eeP5zc0fHQM+82h+5Mhom1+4MI7A99orToT267fxEX/6ceihEV5aejjiyZO37CMvXJjfo+L58zu219bW8yieIrJpSgq51NwczUZTp27R26dPjz2/005xdO4ewykfdVTMf+aZmHf99TH99a/HCdx9943poUOj3f2f/4yxdI491v3WW6MJZ+nSaKtftuyjeWr16jiqnjFjyz+6iPROSgq59Mwzsesefniz39rcHFetjBwZzTjf/GYkiV12iZOeI0bEhUvPPBMnQE86qaP9u7k5xrMfPDj+iohkK9ukoA7xtsQ3vgH33hsjePQwNNTtt0df+bfeGnf/3npr9FX/619H//M33hjLjRsX/eY3NUUP2qWlMZjHSy99tGth9153A7SIJEwd4uVKXV2U3v/rf22UEFpaYhSp0tLo3PSww2L+9dfDW2/FoCEHHBBdGn3yk/H2Y4+NJHDoodGdQnq4wzPOgGnT4tFVX/NKCCKSK6opbK7vfCcO72fO7OjVFPjP/4Tvfa9jsaefjtGXdtsNLrkkOlR7//3oXvmb34xxbzelpSVyz8iROfwcIlJUVFPIhQULYhyEL30Jdt+d996L4fuamuDKK6Pb5J/8JMahvf76GMgcYhC10aOz30xZmRKCiCRDSWFz/PCH0aB/xRWsXRv9569ZA6NSo0rfdFMU/t/4Blx+eUez0eYkBBGRJGk8hWw1NsJ998Hpp8NOO/HYY7BiBRx/fAyJcM01MeYsxCia5eUwfz6cdFKyYYuIbA7VFLL14IORGL72NSDyw+jRcRWR2cYnf4cNi9xx991KCiLSu6imkK3bb4/Lig45hCVL4Kmn4ItfhJKSrq8GuuaayCMTJuQ/VBGRLaWkkI033oAXXohaghkPPACtrXHp6KYMGwannpq/EEVEtgUlhWzceWecJDjjDFpa4ga0/fdXLUBEtj86p9CT1lZ46CE44QQYOpS7fg5vvw2PPJJ0YCIi255qCj3561/hww/htNNYsyYuNT30UJ1AFpHtU06TgplNMrPZZjbHzC7t4vUxZvZHM3vFzF43sxNyGc8WeeCBuENt8mSuvx4WL467l9XVhIhsj3KWFMysFLgZOB7YAzjNzPbotNi/AtPcfV9gKvDTXMWzRTZsgIcfhilTWGv9uPFGmDw5agoiItujXNYUDgTmuPtcd98APAhM6bSMAwNTzwcBH+Qwns33+OOwfDlMncr990N9PVx8cdJBiYjkTi5PNO8ILMiYXggc1GmZK4Gnzex8oD9wdA7j2TyrVsGFF8Luu+PHHsf1+8G++3b0ZyQisj1K+kTzacDd7j4KOAG4z8w+EpOZnWNmM8xsRl1dXX4iu+QSWLQI7rqLp/9UzltvwUUX6VyCiGzfcpkUFgGZXcGNSs3L9BVgGoC7Pw9UADWdV+Tut7n7RHefWFtbm6NwM7z2Gtx2W7QVHXww//Vf0WupbkYTke1dLpPCi8B4MxtnZuXEieTpnZZ5HzgKwMwmEEkhT1WBbjz3XPw97zzefDPGRjjvvLh/TURke5azcwru3mJm5wFPAaXAne4+08yuIsYKnQ5cDPzczC4iTjqf5YUw6s/rr0N1NYwezQ1fg8rK6PlURGR7l9M7mt39SeDJTvMuz3j+FvDJXMawJVa9PIf/U3k3tVcYv/hFjJbW3UhpIiLbC3Vz0VlbG0+/PoKfrZsC/xbjJl94YdJBiYjkh5JCZ/PnM2vdWMycpUuNlhYYMSLpoERE8kNJobPXX2cWE9hpxHpqaiqSjkZEJK+Svk+h8KSSwoS9lC9FpPgoKXTS9tobzLbdmfBxJQURKT5KCp3Mf3kZa72S3XdPOhIRkfxTUsjU1MSseXEeQaOqiUgxUlLI9D//wyyiiqCkICLFSEkh0+OPM6t0L2prXTeriUhRUlJIc4fHH+ftgQcyYYK6QhWR4qSkkDZrFj5vHrM27KyTzCJStJQU0h5/nCUMZ/maCp1PEJGipaSQ9vjj/GWnMwE4+OCEYxERSYiSAkBrKzz3HH8YdDIDB8LEiUkHJCKSDCUFgBUroLWVZxbtzhFHQJluZhaRIqWkAFBXx1zGMXfZII4+OulgRESS02NSMLPzzWxwPoJJTH09z8SooBx1VMKxiIgkKJuawnDgRTObZmaTzGz7u4i/vp4/cDQ71G7Q5agiUtR6TAru/q/AeOAO4CzgXTO72sx2yXFseeNL6/gjR3DU4c1shylPRCRrWZ1TcHcHFqceLcBg4GEzuzaHseXN6kWrqGMYe+9fnnQoIiKJ6vE6GzP7NnAmUA/cDlzi7s1mVgK8C3wvtyHm3uIFzQCMGN0n4UhERJKVzcWXQ4DPufv8zJnu3mZmk3MTVn4t+aAV0FjMIiLZNB/9FlienjCzgWZ2EIC7z8pVYPm0eGmcSBg+POFAREQSlk1SuAVozJhuTM3bbixeFucSVFMQkWKXTVKw1IlmIJqNyK7ZidQlrLPNbI6ZXdrF69eb2aupxztm1pB96NvO4lX9KLVWjaEgIkUvm8J9rpldQEft4JvA3J7eZGalwM3AMcBC4l6H6e7+VnoZd78oY/nzgX03I/ZtZvGaKob3a6SkZFASmxcRKRjZ1BTOBQ4FFhGF+0HAOVm870BgjrvPdfcNwIPAlG6WPw14IIv1bltr17KkZSgjBjXlfdMiIoWmx5qCuy8Fpm7BuncEFmRMpxPKR5jZTsA44Nkt2M7WWbaMxYxg+JDmvG9aRKTQZHOfQgXwFWBPoCI9393P3oZxTAUedvfWTcRwDqnayZgxY7bhZoH6ehYzgr2HdblpEZGikk3z0X3ACOA44M/AKGB1Fu9bBIzOmB6VmteVqXTTdOTut7n7RHefWFtbm8Wms9e2pI4lDGfEDurfQkQkm6TwMXf/v8Aad78H+AybaAbq5EVgvJmNM7NyouCf3nkhM9ud6Dbj+ezD3nZWzF9FC30YMVpdXIiIZJMU0o3tDWb2cWAQMKynN7l7C3Ae8BQwC5jm7jPN7CozOzFj0anAg5mXvebT4vfWATBi535JbF5EpKBkc0nqbanxFP6VONKvAv5vNit39yeBJzvNu7zT9JVZRZoj7f0e7dI/yTBERApCt0kh1endKndfAfwF2DkvUeXR4g+jgjJ8h9KEIxERSV63zUepu5d7fS+o3VlcF8lAXVyIiGR3TuEPZvZdMxttZkPSj5xHlidLVpRTUbKegQOTjkREJHnZnFM4NfX3WxnznO2kKWnx6n6MqGjATF2kiohkc0fzuHwEkpTFTYMYUd1IDEUtIlLcsrmj+cyu5rv7vds+nDxzZ/GGIew8aH3SkYiIFIRsmo8OyHheARwFvAz0/qSwciV11HDQkPqkIxERKQjZNB+dnzltZtVEj6e9ntfVU89O1NYqKYiIQHZXH3W2hujRtNdbNX8FLfShZkRWYwaJiGz3sjmn8N/E1UYQSWQPYFoug8qXZe9Fv35Dd+ibcCQiIoUhm0Pk6zKetwDz3X1hjuLJq/r5awCoGaN+j0REILuk8D7wobuvAzCzSjMb6+7v5TSyPKhfFFcd1YwbkHAkIiKFIZtzCr8C2jKmW1Pzer36JTGwjmoKIiIhm6RQlhpjGYDU8+1i8IH6ujhVMrRGA+yIiEB2SaEuc/wDM5sCbBfXcC5bUUIpLQwalHQkIiKFIZtzCucC95vZT1LTC4Eu73LubepXlVNTvortqH8/EZGtks3Na/8EDjazqtR0Y86jypP6NZXUVK4BlBRERCCL5iMzu9rMqt290d0bzWywmf3/+Qgu1+rXVVHTf13SYYiIFIxszikc7+4N6YnUKGwn5C6kPGlupr61mqGDmnteVkSkSGSTFErNrP2WXzOrBHr/LcDLl1NPDTVDvOdlRUSKRDYnmu8HnjGzuwADzgLuyWVQ+eBL61jG7tQMW5Z0KCIiBSObE83XmNlrwNFEH0hPATvlOrBcWzm/gVbKqBnRJ+lQREQKRra9pC4hEsIpwJHArJxFlCf181K6T0OSAAANcUlEQVSd4e3Y+1vCRES2lU3WFMxsV+C01KMeeAgwdz8iT7HlVP2CtQDUjOmfcCQiIoWju5rC20StYLK7H+buNxH9HmXNzCaZ2Wwzm2Nml25imc+b2VtmNtPMfrk5698a9R9Ezx01Ow/M1yZFRAped+cUPgdMBf5oZr8jRlvLupMgMysFbgaOIe6CftHMprv7WxnLjAcuAz7p7ivMbNgWfIYtsmxpCwA1I3VOQUQkbZM1BXd/1N2nArsDfwQuBIaZ2S1mdmwW6z4QmOPuc1Od6D0ITOm0zNeAm1P3PuDuS7fkQ2yJ+vrIb0OH5muLIiKFr8cTze6+xt1/6e6fBUYBrwD/J4t17wgsyJhemJqXaVdgVzP7m5n93cwmdbUiMzvHzGaY2Yy6urosNt2z+oYyyqyFgWo9EhFpt1ljNLv7Cne/zd2P2kbbLwPGA58mTmj/3Myqu9jube4+0d0n1tbWbpMN16+ppKbPSky9ZouItNuspLCZFgGjM6ZHpeZlWghMd/dmd58HvEMkiZyrX1dFTd/V+diUiEivkcuk8CIw3szGmVk5cdJ6eqdlHiVqCZhZDdGcNDeHMbVr2NCP6gp1hicikilnScHdW4DziDugZwHT3H2mmV2VMWjPU8AyM3uLOJl9ibvnpd+JxpYKBvRVZ3giIpmy6ftoi7n7k8CTneZdnvHcge+kHnnV2FbJuMq1+d6siEhBy2XzUeFyp7GtH1WVm3UvnojIdq84k8K6dTRSRVV/dZstIpKpKJOCN66JpFCVdCQiIoWlKJPChuWNtNCHqgFJRyIiUliKMik01selqFUDivLji4hsUlGWiu1JYVBpwpGIiBSW4kwKy9YDUFWd0ytyRUR6neJMCstjLIWqweo2W0QkU3EmhYYYS6FqaHnCkYiIFJYiTQrRvUXVEI3PLCKSqTiTwso2AKpqKhKORESksBRnUlgddzJXDeuXcCQiIoWlOJNCYyopDNE5BRGRTEWaFGK4tf5VGnZNRCRTcSaFJqOStZTq3jURkY0UZ1JYW0pVaVPSYYiIFJwiTQplVJVqgB0Rkc6KMyms70NVmcZnFhHprDiTwoY+VJVvSDoMEZGCU5xJobmvkoKISBeKMym0VFDVtyXpMERECk5xJoXWSqoqW5MOQ0Sk4BRnUmjrp6QgItKF4ksKra00UkVVf086EhGRgpPTpGBmk8xstpnNMbNLu3j9LDOrM7NXU4+v5jIegJZVTayjkqqqXG9JRKT3ydl4lGZWCtwMHAMsBF40s+nu/lanRR9y9/NyFUdna5auAQZQNSBfWxQR6T1yWVM4EJjj7nPdfQPwIDAlh9vLSmNd3MlcNaD4Ws5ERHqSy5JxR2BBxvTC1LzOTjaz183sYTMb3dWKzOwcM5thZjPq6uq2KqjGZesBqKpWb3giIp0lfbj838BYd98b+D1wT1cLuftt7j7R3SfW1tZu1Qbbk8KgnLWciYj0WrlMCouAzCP/Ual57dx9mbuvT03eDuyfw3gAaFwedzJXDe6T602JiPQ6uUwKLwLjzWycmZUDU4HpmQuY2ciMyROBWTmMB4DGFc0AVA3tm+tNiYj0OjlrQ3H3FjM7D3gKKAXudPeZZnYVMMPdpwMXmNmJQAuwHDgrV/GkNa6Mm9aUFEREPiqnDevu/iTwZKd5l2c8vwy4LJcxdNaeFGoq8rlZEZFeIekTzXnXuLoNgKrayoQjEREpPEWYFOJv1fD+yQYiIlKAii8prIE+bKC8UvcpiIh0VnxJoamE/taUdBgiIgWp6JLCqjWlDCppTDoMEZGCVHRJoaGpnOo+SgoiIl0pvqSwtoJB5euSDkNEpCAVX1JYX0l1pZKCiEhXii4prGzpR3W/DUmHISJSkIouKTS0DqC6f0vSYYiIFKSiSgptbbDKB1A9sC3pUEREClJRJYVVdetxShg0KOlIREQKU1ElhYYF0cdF9WBLOBIRkcJUVElh5YdxJ3P1UHVxISLSlaJKCg0frgWgulajromIdKW4ksLSuBS1ergG2BER6UpxJYW6GIqzeoQG2BER6UpRJYWVy+L+hEE7aCwFEZGuFFVSaFjhAAzasSrhSEREClNxJYUGqGI1ZUMGJh2KiEhBKq6ksLqEalZCX51oFhHpSnElhcYyqktXJR2GiEjBKqqksLKpD4P6aChOEZFNyWlSMLNJZjbbzOaY2aXdLHeymbmZTcxlPA1rK6guX5vLTYiI9Go5SwpmVgrcDBwP7AGcZmZ7dLHcAODbwAu5iiWtYYMG2BER6U4uawoHAnPcfa67bwAeBKZ0sdy/AdcAOS+tG5r7a4AdEZFu5DIp7AgsyJhemJrXzsz2A0a7+xM5jAMAd1jZWkV1VWuuNyUi0msldqLZzEqA/wIuzmLZc8xshpnNqKur26LtrVkDrZRRPUBJQURkU3KZFBYBozOmR6XmpQ0APg78yczeAw4Gpnd1stndb3P3ie4+sba2douCab+bWQPsiIhsUi6TwovAeDMbZ2blwFRgevpFd1/p7jXuPtbdxwJ/B0509xm5CKa92+whRXUVrojIZslZCenuLcB5wFPALGCau880s6vM7MRcbXdTGj7QADsiIj0py+XK3f1J4MlO8y7fxLKfzmUsGmBHRKRnRdOWsrIuNcDOsPKEIxERKVxFkxTSA+wMGtkv4UhERApX0SQF1q6lhjolBRGRbhRNUvjWJ1+ljmH0rRmQdCgiIgWraJICK1fGX92oICKyScWTFMaNg5NOggGqKYiIbEpOL0ktKFOmxENERDapeGoKIiLSIyUFERFpp6QgIiLtlBRERKSdkoKIiLRTUhARkXZKCiIi0k5JQURE2pm7Jx3DZjGzOmD+Fr69BqjfhuFsK4UYl2LKXiHGpZiyV4hx5SKmndy9x/GMe11S2BpmNsPdPzIGdNIKMS7FlL1CjEsxZa8Q40oyJjUfiYhIOyUFERFpV2xJ4bakA9iEQoxLMWWvEONSTNkrxLgSi6mozimIiEj3iq2mICIi3SiapGBmk8xstpnNMbNLE4phtJn90czeMrOZZvbt1PwhZvZ7M3s39XdwArGVmtkrZvZ4anqcmb2Q2l8PmVl5AjFVm9nDZva2mc0ys0OS3ldmdlHqu3vTzB4ws4ok9pWZ3WlmS83szYx5Xe4bCz9Oxfe6me2Xx5j+M/X9vW5mvzGz6ozXLkvFNNvMjstXTBmvXWxmbmY1qem87Kfu4jKz81P7a6aZXZsxP+f7qp27b/cPoBT4J7AzUA68BuyRQBwjgf1SzwcA7wB7ANcCl6bmXwpck0Bs3wF+CTyemp4GTE09/xnwjQRiugf4aup5OVCd5L4CdgTmAZUZ++isJPYVcDiwH/Bmxrwu9w1wAvBbwICDgRfyGNOxQFnq+TUZMe2R+j/sC4xL/X+W5iOm1PzRwFPEPU81+dxP3eyrI4A/AH1T08Pyua/a48j1j7cQHsAhwFMZ05cBlxVAXI8BxwCzgZGpeSOB2XmOYxTwDHAk8Hjqn6I+4595o/2Xp5gGpQpg6zQ/sX2VSgoLgCHEqIWPA8clta+AsZ0KlS73DXArcFpXy+U6pk6vnQTcn3q+0f9gqoA+JF8xAQ8D+wDvZSSFvO2nTXx/04Cju1gub/vK3Yum+Sj9z5y2MDUvMWY2FtgXeAEY7u4fpl5aDAzPczg3AN8D2lLTQ4EGd29JTSexv8YBdcBdqWat282sPwnuK3dfBFwHvA98CKwEXiL5fZW2qX1TKL//s4kjcUgwJjObAixy99c6vZT0ftoV+FSqKfLPZnZAEnEVS1IoKGZWBTwCXOjuqzJf8zgUyNslYWY2GVjq7i/la5tZKiOq17e4+77AGqJJpF0C+2owMIVIWDsA/YFJ+dr+5sj3vumJmf0AaAHuTziOfsD3gcuTjGMTyoha6MHAJcA0M7N8B1EsSWER0YaYNio1L+/MrA+REO5391+nZi8xs5Gp10cCS/MY0ieBE83sPeBBognpRqDazMpSyySxvxYCC939hdT0w0SSSHJfHQ3Mc/c6d28Gfk3sv6T3Vdqm9k2iv38zOwuYDHwhlaySjGkXIqm/lvrNjwJeNrMRCcaUthD4tYd/EDX3mnzHVSxJ4UVgfOoqkXJgKjA930Gksv4dwCx3/6+Ml6YDX0o9/xJxriEv3P0ydx/l7mOJ/fKsu38B+CPwv5OIKRXXYmCBme2WmnUU8BYJ7iui2ehgM+uX+i7TMSW6rzJsat9MB85MXV1zMLAyo5kpp8xsEtE0eaK7N3WKdaqZ9TWzccB44B+5jsfd33D3Ye4+NvWbX0hc/LGYBPdTyqPEyWbMbFfi4op68r2vcnWyotAexJUF7xBn7n+QUAyHEVX614FXU48TiDb8Z4B3iasPhiQU36fpuPpo59QPbw7wK1JXROQ5nk8AM1L761FgcNL7Cvj/gLeBN4H7iCtC8r6vgAeI8xrNRMH2lU3tG+LCgZtTv/03gIl5jGkO0R6e/r3/LGP5H6Rimg0cn6+YOr3+Hh0nmvOyn7rZV+XAL1K/rZeBI/O5r9IP3dEsIiLtiqX5SEREsqCkICIi7ZQURESknZKCiIi0U1IQEZF2SgoiItJOSUFERNopKYiISLv/B6xP0OyFwG/UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trains,'r')\n",
    "plt.plot(evals,'b')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuUFPWd9/H3lxlucpHbSAgDghGToImoxKDRR6MmIhol+7iu7iYiwbDnBF2yR82ju9lHzSYnmnXVeJKYaMiqOXk0GjDiZRMJGl1NoiIichElBgM4MKPCAOogM/N9/vhV261T09Nzqa6+fF7n9OmqX1dXfWsY6ju/S/3K3B0REZEP6pd2ACIiUpqUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrFq0w6gN8aMGeOTJk1KOwwRkbLy7LPPvu7udV1tV9YJYtKkSaxYsSLtMEREyoqZvVrIdmpiEhGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJFZVJ4jt2+Hee9OOQkSkNJX1jXK9deqp8PzzsGcPDBmSdjQiIqWlqmsQGzeG9/b2dOMQESlFVZ0gMszSjkBEpPRUdYJwTzsCEZHSVdUJIkOJQkSko6pOEJmmJfVBiIh0VNUJIlNzUIIQEemoqhNEhpqYREQ6quoEoRqEiEjnqjpBZKgGISLSUVUnCNUgREQ6V9UJIkM1CBGRjqo6QWiYq4hI56o6QaiJSUSkc1WdIDLUxCQi0lFiCcLMBpnZ02b2vJmtNbOro/LJZvaUmW00s1+a2YCofGC0vjH6fFJSsWWoBiEi0rkkaxB7gZPc/XBgGjDTzGYA1wI3uPvBwA5gXrT9PGBHVH5DtF1RqAYhItJRYgnCgz3Rav/o5cBJwK+i8tuB2dHyWdE60ecnmxVnIm7VIEREOkq0D8LMasxsFdAILAP+DOx099Zoky3A+Gh5PLAZIPq8GRgds8/5ZrbCzFY0NTX1SZxKECIiHSWaINy9zd2nAfXA0cDH+mCft7j7dHefXldX1+sYwz77ZDciIhWlKKOY3H0n8ChwDDDCzDLPwq4HtkbLW4EJANHn+wNvJBtXeFcNQkSkoyRHMdWZ2YhoeTDwOWA9IVGcHW02B7gvWl4arRN9/oh7cf62Vw1CRKSj2q436bFxwO1mVkNIRHe7+wNmtg64y8y+DTwHLIq2XwT83Mw2Am8C5yYYG6AahIhIPoklCHdfDRwRU/4KoT/ig+UtwN8mFU8+qkGIiHSkO6lRDUJEJI4SBEoQIiJxlCBQE5OISJyqThDqpBYR6VxVJ4gM1SBERDqq6gShGoSISOeqOkFkqAYhItKREgSqQYiIxFGCQAlCRCSOEgTw5JNw221pRyEiUlqSnIup5GX6Hr7xjfB+wQWphSIiUnJUgxARkVhVnSA0eklEpHNVnSBERKRzShAiIhKrqhOEmphERDpX1QlCREQ6pwQhIiKxlCBERCSWEoSIiMRSghARkViJJQgzm2Bmj5rZOjNba2YLo/KrzGyrma2KXrNyvnOFmW00sw1mdmpSsYmISNeSnIupFbjE3Vea2TDgWTNbFn12g7tfl7uxmU0FzgUOBT4M/M7MDnH3tgRjFBGRTiRWg3D3BndfGS3vBtYD4/N85SzgLnff6+5/ATYCRycVn4iI5FeUPggzmwQcATwVFV1kZqvN7GdmNjIqGw9szvnaFmISipnNN7MVZraiqakpwahFRKpb4gnCzIYCi4Gvu/su4GbgI8A0oAH4z+7sz91vcffp7j69rq6uz+MVEZEg0QRhZv0JyeEX7r4EwN23u3ubu7cDt5JtRtoKTMj5en1U1uf27YMdOzqWa+oNEZGsJEcxGbAIWO/u1+eUj8vZ7IvAmmh5KXCumQ00s8nAFODpJGJbsgRGjepYrkePiohkJTmK6TPAl4EXzGxVVPYvwHlmNg1wYBPwjwDuvtbM7gbWEUZALUhqBNPAgfHl7e1QU5PEEUVEyk9iCcLdnwAs5qOH8nznO8B3koopI1+CEBGRoCrvpB4wIL5cCUJEJKsqE0RnNQh1UouIZClB5FANQkQkSwkihxKEiEiWEkQOJQgRkSwliBxKECIiWUoQOZQgRESylCByKEGIiGQpQeRQghARyVKCyKH7IEREsqoyQdTWQr+YM1cNQkQkqyoTBMRPt6EEISKSVbUJIq6ZSQlCRCSrWwnCzEaa2SeTCqaYlCBERPLrMkGY2e/NbLiZjQJWArea2fVdfa/UxSWI1athzZqO5SIi1aiQ50Hs7+67zOxC4A53v9LMVicdWNLiEsTs2eFdo5lERAprYqqNHhN6DvBAwvEUTWdDXUVEJCgkQXwL+C2w0d2fMbODgJeTDSt5ShAiIvl12cTk7vcA9+SsvwL87ySDKgYlCBGR/ArppP5e1End38yWm1mTmX2pGMElqX//tCMQESlthTQxfd7ddwFnAJuAg4HLkgyqGJQgRETyK6iTOno/HbjH3ZsL2bGZTTCzR81snZmtNbOFUfkoM1tmZi9H7yOjcjOzm8xso5mtNrMje3RGBRoyJMm9i4iUv0ISxANm9iJwFLDczOqAlgK+1wpc4u5TgRnAAjObClwOLHf3KcDyaB3gNGBK9JoP3NytM+mmYcOS3LuISPnrMkG4++XAscB0d98HvAWcVcD3Gtx9ZbS8G1gPjI++e3u02e1AdPcBZxHus3B3/xMwIhpemwglCBGR/LocxWRm/YEvAf/LzAAeA37cnYOY2STgCOApYKy7N0QfbQPGRsvjgc05X9sSlTXklGFm8wk1DCZOnNidMN5n6NAef1VEpCoU0sR0M6F56UfR60i60fxjZkOBxcDXo87u97i7A926b9ndb3H36e4+va6urjtffR/VIERE8itkqo1PufvhOeuPmNnzhew8qn0sBn7h7kui4u1mNs7dG6ImpMaofCswIefr9VFZIlSDEBHJr5AaRJuZfSSzEt1J3dbVlyy0Ry0C1rt77uR+S4E50fIc4L6c8vOj0UwzgOacpqg+pwQhIpJfITWIy4BHzewVwIADgbkFfO8zwJeBF8xsVVT2L8A1wN1mNg94lTDHE8BDwCxgI/B2gcfoMTUxiYjkV8hUG8vNbArw0ahoAzCtgO89QUgocU6O2d6BBV3tt68oQYiI5FdIDQJ33wu8N8W3md0D9HwIUQlQghARya+njxztrGZQNsYldoeFiEhl6GmCKPtH6hxyCCxfnnYUIiKlq9MmJjO7n/hEYMDoxCIqopNOSjsCEZHSla8P4roefiYiIhWg0wTh7o8VMxARESktPe2DEBGRCqcEISIisZQgREQkViHTfceNZmoGVgA/cfdCHh4kIiJlppAaxCvAHuDW6LUL2A0cEq2LiEgFKmSqjWPd/VM56/eb2TPu/ikzW5tUYGnatQsGDgwvEZFqVUgNYqiZvTfvUrScmSz73USiStn++8MJJ6QdhYhIugqpQVwCPGFmfybcRT0Z+JqZDSH7bOmK89RTaUcgIpKuQqb7fiia7vtjUdGGnI7pGxOLTEREUlXQdN+EZ1JPirY/3Mxw9zsSi0pERFJXyDDXnwMfAVaRfdSoA0oQIiIVrJAaxHRgavTEt4rTrx+0t6cdhYhI6SlkFNMa4ENJB5KWSZPSjkBEpDQVUoMYA6wzs6eBvZlCdz8zsaiKaNIkeOWVtKMQESk9hSSIq5IOIk2TJ6cdgYhIaeqyicndH4t7dfU9M/uZmTWa2ZqcsqvMbKuZrYpes3I+u8LMNprZBjM7teen1D0zZxbrSCIi5aXTBGFmT0Tvu81sV85rt5ntKmDftwFxl98b3H1a9HooOsZU4Fzg0Og7PzKzmu6eTE+cfTY88kgxjiQiUl7yPVHuuOh9WE927O6Pm9mkAjc/C7jL3fcCfzGzjcDRwB97cuzuOuywYhxFRKS8FPQ8CDOrMbMPm9nEzKsXx7zIzFZHTVAjo7LxwOacbbZEZXGxzDezFWa2oqmpqRdhZPXTUzFERDro8tJoZhcD24FlwIPR64EeHu9mwk1304AG4D+7uwN3v8Xdp7v79Lq6uh6G8X5KECIiHRUyimkh8FF3f6O3B3P37ZllM7uVbKLZCkzI2bQ+KisKJQgRkY4KuTRuJjxBrtfMbFzO6hcJN+EBLAXONbOBZjYZmAI83RfHLIQShIhIR4XUIF4Bfm9mD/L+G+Wuz/clM7sTOBEYY2ZbgCuBE81sGmEup03AP0b7WmtmdwPrgFZggbu3xe03CWbFOpKISPkoJEH8NXoNiF4FcffzYooX5dn+O8B3Ct1/X1INQkSko0KeB3F1MQJJU2cJYvBguPlmuOCCooYjIlISChnFdIiZ3WJmD5vZI5lXMYIrls4SREsLXHJJcWMRESkVhTQx3QP8GPgp2edBVJR8TUzqnxCRalVIgmh195sTjyRF6oMQEemokEvj/Wb2NTMbZ2ajMq/EIyuifLUE1SBEpFoVUoOYE71fllPmwEF9H046lARERDoqZBRTVT8xQclDRKpVlwnCzM6PK3f3O/o+HBERKRWFNDF9Kmd5EHAysBKoqARRWwutrWlHISJSOgp5otzFOa+vAkcCQ5MPrbjq6+PL330XvvpV2LatuPGIiKStJwM83wIqrl/ib/4mvry5GX76U7j00uLGIyKStkL6IO4njFqCkFCmEm6eqyjf+x4ceCAsXBj/uXt8uYhIpSqkD+K6nOVW4FV335JQPKmpqYHDD+/8c41mEpFqU8gw18dy182sn5n9g7v/Irmw0lFT0/lnShAiUm067YMws+FmdoWZ/cDMPm/BRYTnQ5xTvBCLR1NuiIhk5bsk/hz4KPACcCHwKPC3wGx3P6sIsRVdvgTR2Ahf+Qq8807x4hERSVO+JqaD3P0TAGb2U6ABmOjuLUWJLAX5mpgefji8n3ACzJnT+XYiIpUiXw1iX2YhevznlkpODqAmJhGRXPlqEIeb2a5o2YDB0boB7u7DE4+uyJQgRESyOk0Q7p6nwaUyFZIgNJpJRKqF/mbOka8PIuP55+Gii3TjnIhUvsQShJn9zMwazWxNTtkoM1tmZi9H7yOjcjOzm8xso5mtNrMjk4orn0JqENdfDz/8IWzfnnw8IiJpSrIGcRsw8wNllwPL3X0KsDxaBzgNmBK95gOpPOK0O30QamoSkUqXWIJw98eBNz9QfBZwe7R8OzA7p/wOD/4EjDCzcUnF1plCmpgy2tuTi0NEpBQUuw9irLs3RMvbgLHR8nhgc852W6KyDsxsvpmtMLMVTU1NfRrcwIGFb7tvX9fbiIiUs9Q6qd3dyc4S253v3eLu0919el1dXZ/GNHEiXHxxYdu++y60tfXp4UVESkqxE8T2TNNR9N4YlW8FJuRsVx+VFd1NN8GiRV1vd/rp4Sl0IiKVqtgJYimQmahiDnBfTvn50WimGUBzTlNU0RXSF/HSS8nHISKSpsT+BjazO4ETgTFmtgW4ErgGuNvM5gGvkp0V9iFgFrAReBuYm1RchehOZ7WISKVKLEG4+3mdfHRyzLYOLEgqlu7qToLYsyfcNDdsWHLxiIikQa3oMbqTIEaOhNZW3VktIpVHU23E6E6CaG1NLg4RkTQpQcToSR/Eb34Da9f2fSwiImlRE1OMniSI004L72pqEpFKoRpEjN6MYnrttXATnYhIuVOCiDFyZM+/O348zE11kK6ISN9QgogxYwZMmdLz7y9Z0nexiIikRQkihhmsXw9XXdXz74uIlDsliE7U1MDgwT377jvvwOzZsGIFLFgALS19G5uISDFoFFMevZmM7777wgtg2jT46lf7JiYRkWJRDSKPvpqTSQ8XEpFypASRx5AhfbOf9vYwZ5OISDlRgsjji1/sm/1ceWWYzG/Xrr7Zn4hIMShB5DF6dJhC4+Mf791+Mk9GvfhimDy593GJiBSDEkQXTj0Vjj++b/Z1xx2waRNcfTVcdlnf7FNEJClKEAXo60eLXnUVXHddmAlWHdgiUqqUIArQv39y+/3sZ5PZt4hIbylBFOCEE5Lb9+OPhxrFb38b7sB+8MHkjiUi0h1KEAWYPTtcxJN6VvXVV8PMmWH5G9+AY46Bbdvgr39N5ngiIoVQgiiAWRiqeuyxyR9r3Tr405+gvh4OPBAaG5M/pohIHCWIbhg3rnjHamsL72++WbxjiojkSmUuJjPbBOwG2oBWd59uZqOAXwKTgE3AOe6+I434OnPzzWHU0a9+Vbxj/u53YXjsoEGhNtHUBIcdBv/2b+Hztrbkmr5EpLqZp/CMzChBTHf313PKvge86e7XmNnlwEh3/z/59jN9+nRfsWJFssHGGD4cdu8u+mHf54ILQuf53Llw661w4YXpxiMi5cPMnnX36V1tV0pNTGcBt0fLtwOzU4wlr//5H7jxxnRjuO227JPrFiwI/SQrV6YakohUmLQShAMPm9mzZjY/Khvr7g3R8jZgbNwXzWy+ma0wsxVNmTksiuzww8O0GaUi8wzs3/wmvDc1wdNPZz9/+ml48cXixyUi5S2t50Ec5+5bzewAYJmZve/y5e5uZrFtX+5+C3ALhCam5EON16+U6l6RxYvhX/8VDjgg9FcceyysXQvNzeHzFFoTRaSMpXKZc/et0XsjcC9wNLDdzMYBRO8lP8Bz0SJ47rm0o8jKNDFlhsb+4Q/Z5AAh3nXr4Ikn9JQ7Eela0ROEmQ0xs2GZZeDzwBpgKTAn2mwOcF+xY+uur3wlPC3ujTfgW99KO5quXXghHHpomHxw4UL44x/DfFDr12e3WbwYvv/99GIUkdJR9FFMZnYQodYAoYnr/7n7d8xsNHA3MBF4lTDMNe9dAGmNYoqzciUcdVToLC6nppwJE2DzZvja1+Cuu7L3XTQ3h0kKV68OU5Rv2hT6Xtx7/qxuESkNhY5iSmWYa18ppQQB0NAQ7pH4p39KO5K+MXYsbN+eXf/oR2HDBvjyl+HnP4ctW2D8+HAvhns49yFDwhTptbWl2U8jIuU5zLXsjRsX7k948EH4/e9h+nQYMSLtqHouNzlASA4QkgOEYbZmcOKJYWba886DM8+EgQPh7/4u+7116zrWqjZvhlWrsuu7d2dHY4lIaVANImFbtoRmnGp07bVQVxf6av7rv0Ly/NGP4J//OZsM7rkHBgyAs86CU06BZctSDVmkKqiJqYS4h4vjnj2wZEna0aTj9NNhv/1CQujKD34A8+eH5LpwIcyYEYbvXnllqJndeWf2xsD6+lBT+/GPQyLqDffwUtOYVDoliBK1aBG8/Xbl9FMkacCAwpudRo0KTV8HHACzZsG8eXDNNWEY8pYtMGVKmEfr0UdDX8rJJ4dkcNddIXHNng3nnx/mvdq1C4YNK+y4ra2h76laa4lSnpQgSti+fXDOOeHZDy0t8Mgj8O1vpx1V9fnCF+D++zuWX3556B+5887QAT96dMdtnnkGjj46u4/t20Ny+sxnwnM8Nm9OPn6Rnio0QaR1J3VV698f7r03u/7GG+nFUs3ikgOEmgeE/pPW1lCzmDYt9J/MnRuauzJTv2f2sWlTaEL8wx8SD1ukaFSDKAHt7aGZYseO0El75ZVhVM+ll8J116UdnfREGf+3kiqgJqYy9uyz8Nprofliz57Q3LH//vDJT6YdmRSqvT10pIuUIt0HUcaOOiokB4ChQ+G44+ATn4Bf/jJMNQ7ZkTYHHhjex48vfpzSuT170o5ApPeUIMrIOeeEZLFjR5jS+6ab4OWXYe/e0Cna0BDKAEaOhIMPTjfearZzZ9oRiPSeEkQZGjEiDOu8+OLQ4T1gQGjO+NCHQtnWraHj+8UXQ1J5/PEwMV/mAUNf+EK4f+CEE9I9j0p2yCFw2WVpRyHSO+qDqDL79oWkAmGETktLdiTOypWwbVtovpo7Fx54IEwN/olPhKGeDz4Ia9akF3s5KuP/XlLB1EktiVi6NNRGamtDk9bo0WFSv0su6bjtrFkwZky4+Qzgm98MTWM/+UnHbQ85JHTsbtyYbPzFVsb/vaSC6T4IScSZZ4bXB/XrF6bTMAu1jFmzQtMXwJe+BE8+CVddFdYvuigkljlz4O//Hk47LdxkZga33x6mJbnxxtCMNnduuFkt7njt7V3H+tJL2cetnn46PPUUvP46zJwZHsX6Zt4J5Xtn6NDk9i1SDKpBSElxD53wo0aF9Y0bQyf84MEwfHiovRx1VLiJ7Y03QtI59dTwwKYlS8LDjw47LGybmUn3mWdCTWby5LDe0gKDBoXlhgb49a9D5/+oUSFp7dgRRoft3QtHHglnnAH/8R+hltPQEBJTplYEYaLB1lb49KfDfv7938OUHmPGhBqTSKlRE5NID2RqJfkm7GttDX01ixeHPpq4CQi/+U347ndDn48m/5NSo/sgRHqgX7+uL+i1tWEU2MKFnc9OO2pUSDbz5oVRZCLlSAlCJAGZJrLbbgvDiU85JcwsK1JOlCBEEpBJEBnLl8OFF4bRXrt3pxOTSHdpFJNIAg44oGPZypXhtX59eEbFpZeGqd6vuy50nNfXFz9OkXxKrpPazGYC3wdqgJ+6+zWdbatOailVbW2heWnxYvjv/y7sOzNmwKGHhhFaM2eGZ0yccgo89li4+72mJux39+4wlYq7JgSUninLUUxmVgO8BHwO2AI8A5zn7uvitleCkFK3dy88/HC4D+Taa3u+n49/PIyeOvjgkHDOPjsM8z377JBQ+vWDqVPDdPFnnBFmAP7sZ0ON5bDD4IUX4Pjjw9MM33kn3KMyYkRIOrt2hWHBbW2hA14qX7kmiGOAq9z91Gj9CgB3/27c9koQUk5aWsJ7ZlTTr38dmpteeCFcpPftS/b4/fqFxJCJY8yYcBf8yy+Hezz+8peQZF57LXSsb98eyrdvDwlk0KDQdDZ2LKxbF5rEMgmpsTHcZ/Lcc+E+lR074IgjwiNjGxvDd156KSS4J5+Ek04KSezoo7PH2bQpvO+3X4ipvj6MBBs7NtzgeNxx0Nwc5hzbsSPUoBoawnatrWF9yJBwHpMmhfMcPRpeeSVss2FDSLRvvQUDB4bvDBgQfi579oRzbGoKx8vci7NjR6itvfNO2H9bW9i+tjYk/6FDQ41uxIhwHh/6UIhxv/3CPtvbw7/rwIEhGdfWhuXM8XbtClP579sXPmtpCVPhtLaG2mG/fmF54MCQ3IcMCdvst1/vfhfKNUGcDcx09wuj9S8Dn3b3i+K2V4KQStHWFi4aq1eHC+ymTeFic+ed8JGPhNl63347fG4WbuR7++3w7BCzcF/G0KHhwvH66+GC1twcyqdMCRfSSpmCvLY2XDTj7qY3CxfyzGeZbTMyF98BA7IXYbNwgR40KFx8Bw8OP7/M+vDh4WeXe1wIy0OHhs8y70OGhASU2Udt7fuTSltbuNi/9VZ47nmmuXDnzpCQdu4M/4Z792aHXL/7bth/c3PY/549IeFdfHF4bHFPVOxUG2Y2H5gPMHHixJSjEekbNTXhL8njjw/rU6eG9wUL+vY4u3eHi9Tw4eHC+O674aLZ1BQuPk1NITFt3Roujlu3wsc+Fi5o27aFi9muXfDhD4f1+vpQmxg/Hl59NXze3By2b28PF7v29vCdsWPDX9n19bB2bVh/551w/M2bw0W1rS3UOIYNCwmwf/9Q1tIS3gcMCBfzYcPChdIslGfutG9qCscYNizUkHbvDu+NjeFca2qy+8jcTV9TE5LKW2+Fn8Hu3SHuffvCe2NjuEBnths8OJuYduwIn+3cGY65d2+25mEW4ncP22cSEoTylpbs3fZDhoTvDBkSfiaZOFtaQu2kuTkcp7U1bLNtW/ZZMEkqtRqEmphERBJWrndSPwNMMbPJZjYAOBdYmnJMIiJVqaSamNy91cwuAn5LGOb6M3dfm3JYIiJVqaQSBIC7PwQ8lHYcIiLVrtSamEREpEQoQYiISCwlCBERiaUEISIisZQgREQkVkndKNddZtYEvNrDr48BXu/DcMqFzru66LyrS6HnfaC713W1UVkniN4wsxWF3ElYaXTe1UXnXV36+rzVxCQiIrGUIEREJFY1J4hb0g4gJTrv6qLzri59et5V2wchIiL5VXMNQkRE8qjKBGFmM81sg5ltNLPL046nL5nZz8ys0czW5JSNMrNlZvZy9D4yKjczuyn6Oaw2syPTi7x3zGyCmT1qZuvMbK2ZLYzKK/rczWyQmT1tZs9H5311VD7ZzJ6Kzu+X0fT5mNnAaH1j9PmkNOPvDTOrMbPnzOyBaL3izxnAzDaZ2QtmtsrMVkRlifyeV12CMLMa4IfAacBU4Dwzm5puVH3qNmDmB8ouB5a7+xRgebQO4WcwJXrNB24uUoxJaAUucfepwAxgQfTvWunnvhc4yd0PB6YBM81sBnAtcIO7HwzsAOZF288DdkTlN0TblauFwPqc9Wo454zPuvu0nCGtyfyeu3tVvYBjgN/mrF8BXJF2XH18jpOANTnrG4Bx0fI4YEO0/BPgvLjtyv0F3Ad8rprOHdgPWAl8mnCzVG1U/t7vPOFZK8dEy7XRdpZ27D041/roQngS8ABglX7OOee+CRjzgbJEfs+rrgYBjAc256xvicoq2Vh3b4iWtwFjo+WK/FlETQhHAE9RBeceNbWsAhqBZcCfgZ3u3hptkntu75139HkzMLq4EfeJG4FvANHToRlN5Z9zhgMPm9mzZjY/Kkvk97zkHhgkyXJ3N7OKHbpmZkOBxcDX3X2XZZ4ST+Weu7u3AdPMbARwL/CxlENKlJmdATS6+7NmdmLa8aTgOHffamYHAMvM7MXcD/vy97waaxBbgQk56/VRWSXbbmbjAKL3xqi8on4WZtafkBx+4e5LouKqOHcAd98JPEpoXhlhZpk/AHPP7b3zjj7fH3ijyKH21meAM81sE3AXoZnp+1T2Ob/H3bdG742EPwiOJqHf82pMEM8AU6IRDwOAc4GlKceUtKXAnGh5DqF9PlN+fjTSYQbQnFNNLSsWqgqLgPXufn3ORxV97mZWF9UcMLPBhH6X9YREcXa02QfPO/PzOBt4xKPG6XLh7le4e727TyL8/33E3f+BCj7nDDMbYmbDMsvA54E1JPV7nnaHS0qdPLOAlwhttf+adjx9fG53Ag3APkJ74zxCe+ty4GXgd8ANPs3AAAAAj0lEQVSoaFsjjOj6M/ACMD3t+Htx3scR2mZXA6ui16xKP3fgk8Bz0XmvAf5vVH4Q8DSwEbgHGBiVD4rWN0afH5T2OfTy/E8EHqiWc47O8fnotTZz/Urq91x3UouISKxqbGISEZECKEGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiIS6/8DQ+ddtzfeQ54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses,'b')\n",
    "plt.ylabel('Running Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(),'RESNET56')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
